---
title             : |
  Sampling Strategies in Decisions from Experience: Property Representation and Probability Weighting Approximation
  
shorttitle        : "Sampling strategies"

author: 
  - name          : "Linus Hof"
    affiliation   : "1"
    corresponding : yes
    email         : "linushof@posteo.de"
    
affiliation:
  - id            : "1"
    institution   : "Heidelberg University"
    
authornote: |
 This manuscript is a dynamic document created from the materials provided on the accompanying `GitHub` repository: https://github.com/linushof/sampling-in-dfe. The current version of the manuscript, created from the commit with the hash ``r repro::current_hash()``, is submitted as a master's thesis in fulfillment of the requirements for the degree Master of Science (M.Sc.) at Heidelberg University, Faculty of Behavioural and Cultural Studies, Institute of Psychology. Matr.-Nr.: 3588450. Supervisors:
  
  \indent
  1. Prof. Dr. Thorsten Pachur, delegated by Prof. Dr. Klaus Fiedler
  
  \indent
  2. Dr. Veronika Zilker, delegated by Prof. Dr. Jan Rummel
 
abstract: |
  In the sampling paradigm, people can---as much as they want, in the way they want, and without costs---sample the possible outcomes of prospects before making a final choice. Do the sequential pattern in which the outcomes are sampled (sampling strategy) and the way the sampled outcomes are integrated and processed to evaluate the prospects (decision strategy) act together to shape the choice? This paper presents two models that incorporate the potential interplay between both types of strategies into the computational framework of sequential sampling models. Each model assumes an evidence accumulation process representing a distinct decision strategy and is used to simulate choices between a safe and a risky prospect, while systematically varying sampling strategies. The simulations show that the potential interplay between both types of strategies can lead to systematically different choice patterns and can contribute to the as-if underweighting of rare outcomes pattern in decisions from experience, irrespective of the existence or absence of sampling error. The model-implied differences in the choice patterns translate to distinct signatures in the psychoeconomic functions of cumulative prospect theory.
  
keywords          : "decisions from experience, information sampling, evidence accumulation, computational modeling, cumulative prospect theory"
wordcount         : "12,442"

bibliography      : references.bib
csl               : "C:/Users/Linus Hof/Documents/Psychologie/ARC/sampling-in-dfe/apa.csl"
appendix          : 
  - "manuscript_appendix.Rmd"

figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : no
linkcolor         : "blue"
link-citations    : true
mask              : no
draft             : no

classoption       : "man"
documentclass     : "apa7"
output            : papaja::apa6_pdf

header-includes:
   - \usepackage[capposition=top]{floatrow}
---

```{r setup, include=FALSE}
# set global chunk options
knitr::opts_chunk$set(echo = FALSE, 
                      fig.align = "l", 
                      fig.pos = "t", 
                      fig.height=7, 
                      fig.width=10)
```

```{r packages, include=FALSE}
# load required packages
pacman::p_load(papaja,
               tidyverse,
               viridis,
               viridisLite,
               ggpubr,  
               latex2exp, 
               scico 
               )
```

```{r data, include=FALSE}
# load and prepare required data

## choice data

### specify column types
cols_choices <- list(.default = col_double(),
                     boundary = col_factor(),
                     gamble = col_factor(),
                     rare = col_factor(),
                     agent = col_factor(),
                     choice = col_factor())

### load data files from round-wise and summary model
choices_roundwise <- read_csv("data/choices_roundwise.csv", col_types = cols_choices)
choices_summary <- read_csv("data/choices_summary.csv", col_types = cols_choices)

### merge data files 
choices_roundwise <- choices_roundwise %>%
  mutate(model = "roundwise") %>% 
  select(model, everything())

choices_summary <- choices_summary %>%
  mutate(model = "summary") %>% 
  select(model, everything())

choices <- bind_rows(choices_roundwise, choices_summary)

## cpt estimates
cols_cpt <- list(.default = col_double(),
                 boundary = col_factor(),
                 a = col_factor(),
                 parameter = col_factor())

cpt_roundwise <- read_csv("data/cpt-parameters_roundwise.csv", col_types = cols_cpt)
cpt_summary <- read_csv("data/cpt-parameters_summary.csv", col_types = cols_cpt)

cpt_roundwise <- cpt_roundwise %>%
  mutate(model = "roundwise") %>% 
  select(model, everything())

cpt_summary <- cpt_summary %>%
  mutate(model = "summary") %>% 
  select(model, everything())
  
cpt <- bind_rows(cpt_roundwise, cpt_summary)
```

<!-- Introduction -->

The human mind is a cognitive system that operates on inputs from an environment or memory, and in the domain of decision making, such inputs provide information about the alternatives between which people can choose.
Let a prospect (or: gamble) be a choice alternative that possesses only two kinds of fundamental properties: the possible outcomes of the alternative (e.g., gains or losses of some amount) and the probabilities with which these outcomes occur following the choice of the alternative.
Importantly, the information that the inputs provide about these properties can come in different forms.
Specifically, in *decisions from description* (DFD), the inputs take the form of explicit and complete descriptions of all outcomes and probabilities.
In this case, people make decisions under risk, provided that choosing one of the prospects does not inevitably lead to a particular outcome.
Yet, in *decisions from experience* [DFE, @hertwigDecisionsExperienceEffect2004], the same properties are latent and therefore not known with certainty, but they must be inferred from the relative frequencies with which the outcomes occurred in the past, e.g., when the prospects were chosen in similar past decisions.
In other words, in DFE, the inputs take the form of sampled outcomes, with the lack of precise knowledge about all possible outcomes and their probabilities rendering the decision one under uncertainty rather than just risk.
The differences in the input formats between DFD and DFE are illustrated in the following `code example`:

```{r code-example, echo=TRUE}
# define prospect with two outcomes: 6 with 20%, 0 otherwise (80%)
outcomes <- c(6, 0)
probabilities <- c(.2, .8)

# input to decisions from description
input_DFD <- data.frame(outcomes, probabilities)
print(input_DFD)

# input to decisions from experience, here: 10 sampled outcomes
set.seed(2022)
input_DFE <- sample(outcomes, size = 10, prob = probabilities, replace = T)
print(input_DFE)
```

Although these distinct input forms may in principle carry the same information about a given set of prospects, behavioral decision research has so far produced a large body of papers indicating that there are robust differences between the choices that are made in DFD and DFE, leading to the notion of the *description-experience gap* [@hertwigDescriptionexperienceGapRisky2009].
In one reading of the gap,^[<!--Open footnote-->See @hertwigConstructbehaviorGapDescription2018, for a discussion on the interpretation of the gap.<!--Close footnote-->]
choice patterns in DFD deviate from the normative solutions of expected value (EV) maximization, as if small-probability outcomes are given more weight than would be warranted by their objective probabilities (*as-if overweighting of rare outcomes*);
in turn, in DFE, choice patterns deviate from the solutions of EV maximization, as if the same small-probability outcomes are given less weight than would be objectively warranted [*as-if underweighting of rare outcomes*, e.g., @barronSmallFeedbackbasedDecisions2003; @hertwigDecisionsExperienceEffect2004; @weberPredictingRiskSensitivity2004; @erevAnomaliesForecastsDescriptive2017; @regenwetterConstructbehaviorGapBehavioral2017; see @wulffMetaanalyticReviewTwo2018, for a comprehensive meta-analytic review].
More generally, in DFD, people choose as if small-probability outcomes are more probable than they objectively are, and in DFE, people choose as if the same small-probability outcomes are less probable.

What causes the description-experience gap?
A common notion is that of the mind being sensitive to the information provided by the small number of sampled outcomes that people tend to rely on in DFE [see @foxDecisionsExperienceSampling2006; @hertwigDecisionsExperienceEffect2004; @hertwigDecisionsExperienceWhy2010; @rakowBiasedSamplesNot2008; @wulffMetaanalyticReviewTwo2018].
Specifically, small samples---i.e., sets of sampled outcomes---often differ from descriptions in the information they actually provide about the prospects because they tend to underrepresent small-probability outcomes (Box \hyperlink{box}{1}, see also for illustrative purposes the `code example`, where the objective probability of outcome `6` is `.2`, and the sampled relative frequency is `.1`).
This distortion of the sampled information (sampling error) is then assumed to carry over to the decision-making process, eventually causing, ceteris paribus, distinct choice patterns in DFD and DFE.
\newline

\noindent
\fbox{
    \parbox{\textwidth}{
        \textbf{\hypertarget{box}{Box 1.}} 
        \textit{Reliance on Small Samples in DFE.}
        The binomial distribution of an outcome is the probability distribution of the number of times an outcome occurs in a sample.
        According to the \textit{de Moivre-Laplace theorem} (see, e.g., \protect\hyperlink{ref-georgiiStochastikEinfuhrungWahrscheinlichkeitstheorie2015}{Georgii, 2015}), the binomial distribution can be approximated by a symmetric normal distribution given a large sample.
        That is, the relative frequency with which an outcome occurs in a large sample is predicted to correspond to the objective probability of the outcome most of the time and is not predicted to be lower more often than higher or vice versa.
        However, for small samples, the binomial distribution associated with a small-probability outcome is positively skewed, causing the relative frequency with which this outcome occurs in the sample to be smaller rather than larger than its objective probability.
        That is, small-probability outcomes tend to be underrepresented in small samples.
        An explanation for the as-if underweighting of rare outcomes pattern may thus build on the assumption that the mind is sensitive to the information provided by small samples (\protect\hyperlink{ref-hertwigDecisionsExperienceEffect2004}{Hertwig et al., 2004}; \protect\hyperlink{ref-plonskyRelianceSmallSamples2015}{Plonsky et al., 2015}; see also \protect\hyperlink{ref-erevChoicePredictionCompetition2010}{Erev et al., 2010}, \protect\hyperlink{ref-erevAnomaliesForecastsDescriptive2017}{2017}, for the performance of models assuming reliance on small samples in prediction competitions).
    }
}
\newline
(ref:references-box-1) @georgiiStochastikEinfuhrungWahrscheinlichkeitstheorie2015; @hertwigDecisionsExperienceEffect2004; @erevChoicePredictionCompetition2010; @plonskyRelianceSmallSamples2015; @erevAnomaliesForecastsDescriptive2017

Yet, peoples' reliance on a small number of sampled outcomes in DFE, and the associated sampling error are presumably not the sole cause of the description-experience gap [see @hauDescriptionexperienceGapRisky2008; @ungemachAreProbabilitiesOverweighted2009; @wulffMetaanalyticReviewTwo2018, who show that the as-if underweighting of rare outcomes pattern may appear, even if the overall number of sampled outcomes is large and the relative frequencies closely resemble the latent objective probabilities].
Rather, the specifics of the actual decision-making process---i.e, how the mind exercises the capacity of making decisions from experience as opposed to descriptions---might contribute to the gap.
In experimental studies of DFE using the *sampling paradigm*, people can, as much as they want, sequentially sample the outcomes of two latent prospects according to their objective probabilities before making a final, consequential choice between the prospects [see @hertwigDescriptionexperienceGapRisky2009, see also Fig.\ \@ref(fig:sampling-paradigm)].
Because in the sampling paradigm people cannot rely on the descriptions of outcomes and probabilities to make a decision, but are required to learn about the prospects from experiential sampling of outcomes over time, the tasks involved in the decision-making process differ from those in DFD.
That is, in order to model the process by which people arrive at the final choice in the sampling paradigm, one must explicate a number of assumptions concerning, in particular, the sampling process and the mind's operations on the sequence of sampled outcomes, which are of no relevance to DFD whatsoever, e.g.: How the mind

* decides when to switch between prospects during the sampling phase;

* decides when to stop sampling;

* integrates the information obtained from the sampled outcomes.

\noindent
The questions of interest are then how the mind solves these tasks and, subordinate to that,^[<!--Open footnote-->
As van Rooij and Baggio [-@vanrooijTheoryTestHow2021] put it: "Only in the manner in which we postulate that
such capacities [i.e., decision making] are exercised do our explanations of capacities come to imply effects [e.g., as-if underweighting of rare outcomes]" (p. 682, square brackets added).
<!--Close footnote-->]
whether this leads to choice patterns that are consistent with an as-if underweighting of rare outcomes pattern, irrespective of the existence or absence of sampling error.

While approaching the above questions, the current paper focuses on the effects of the potential interplay between sampling and decisions strategies.
Figure\ \@ref(fig:sampling-paradigm) displays what Hills and Hertwig [-@hillsInformationSearchDecisions2010] considered to be paradigmatic instances of both types of strategies. 
Sampling strategies refer to the sequential pattern with which people sample outcomes from the two prospects over time.
That is, in the sampling paradigm, people can decide without costs when to sample outcomes from which prospect and when to switch between them.
They can do so entirely randomly, resulting in no discernible sequential sampling pattern, or they proceed more systematically.
Hills and Hertwig [-@hillsInformationSearchDecisions2010] proposed that people may either switch just once between prospects (comprehensive sampling) or after each sampled outcome (piecewise sampling).^[<!--Open footnote-->
Note that in their analysis of empirical sampling data,  Hills and Hertwig [-@hillsInformationSearchDecisions2010] used the number of switches between prospects relative to the overall number of sampled outcomes from both prospects (switching frequency) as an approximate measure for the two proposed sampling strategies, and acknowledged that "many [sampling] strategies will fall on the continuum in between [the two paradigmatic strategies]" (p. 1788).
<!--Close footnote-->]
Decision strategies refer to the way people integrate the information obtained from the sampled outcomes in order to evaluate the prospects and make a corresponding choice.
Hills and Hertwig [-@hillsInformationSearchDecisions2010] proposed that people compare the prospects either on the basis of the means across all sampled outcomes (summary decision) or they compare two sampled outcomes---i.e., one from each prospect---over repeated rounds and choose the prospect that won the majority of such comparisons (round-wise decision).
In more general terms, whereas sampling strategies determine how the information about prospects are collected, decision strategies determine how the collected information are processed, or transformed, to arrive at a final choice.

\begin{figure}[t!]
\caption{Possible Sampling and Decision Strategies in the Sampling Paradigm and Their Impact on the Final Choice}
\includegraphics{manuscript_files/sampling-paradigm} \label{fig:sampling-paradigm}
\raggedright \textit{Note.} In the sampling paradigm, people are offered the choice between at least two prospects (here: violet vs. orange), whose exact properties (outcomes and probabilities) remain hidden. To learn about the properties, people can, as much as they want, sample the prospects' outcomes according to their probabilities. Sampling strategies: Refer to the sequential pattern with which people sample the outcomes from both prospects over time. People may switch infrequently (comprehensive sampling) or frequently (piecewise sampling) or with a frequency somewhere in between. Decision strategies: Refer to the way people integrate the sampled outcomes in order to evaluate the prospects. People may integrate all outcomes stemming from the same prospect in order to compute and compare summary scores (summary decision); or they integrate and compare outcomes of the two prospects over repeated rounds (round-wise decision).  
\end{figure}

To provide an explanation for the as-if underweighting of rare outcomes pattern and the related description-experience gap, Hills and Hertwig [-@hillsInformationSearchDecisions2010] suggested a systematic link between both types of strategies.
Specifically, they assumed that comprehensive sampling is associated with making summary decisions, while piecewise sampling is associated with making round-wise decisions.
Since in round-wise decisions small-probability outcomes are expected to be left unconsidered in the majority of comparisons---each of which is weighted equally---, such a coupling could translate to an as-if underweighting of rare events pattern, even if a large number of outcomes is sampled.
That is, if the prospect that is more likely to produce a higher outcome most of the time does *not* also possess a higher EV, round-wise decisions are expected to cause deviations from the solutions of EV maximization that take the form of an as-if underweighting of rare outcomes pattern (see Fig.\ \@ref(fig:sampling-paradigm), for illustrative purposes).
Pointing to the suggested coupling of sampling and decision strategies, Hills and Hertwig [-@hillsInformationSearchDecisions2010] found that a larger proportion of the choices of people who, on average, switched infrequently between prospects were better predicted by a summary strategy (rather than a round-wise strategy), and that this predictive pattern reversed for people who switched frequently.
Moreover, simulating both round-wise and summary decisions on the basis of peoples' sampled outcomes, they showed that round-wise decisions led to a higher proportion of choices that are consistent with an as-if underweighting of rare outcomes.

To summarize the preceding paragraphs: 
Since small samples may distort the information about the properties of latent prospects, a great deal of research on the sampling paradigm has been invested into the question of which factors affect how much people sample [see @wulffAdaptiveExplorationWhat2019, Table 7.2, for a recent summary of relevant factors and papers].
Assuming that people proceed systematically when sampling outcomes, and that their sampling strategies are systematically related to decision strategies, Hills and Hertwig [-@hillsInformationSearchDecisions2010] emphasize that in order to understand how people make DFE and how this comes to imply certain choice patterns, one might need a richer understanding of peoples' sampling behavior.
That is, not only do we need to know how many outcomes are sampled, but also in what way they are sampled, and how this affects the way the obtained information is processed to evaluate the latent prospects.

While offering a novel, convincing inroad into the broader question of how sampling and information-processing can act together to shape DFE in environments where people can sample without costs,^[<!--Open footnote-->
Meaning that people do not gain/loose the amount of each sampled outcome. Of course, sampling implies other costs, such as time and cognitive capacities.
<!--Close footnote-->]
Hills and Hertwig's [-@hillsInformationSearchDecisions2010] work invites some objections, both theoretical and methodological.
The following gaps and problems stand out:

1. *No formal modeling/unstated theoretical commitments:*
The authors provide a verbal description of their theoretical claims, but no formal specification or computational implementation thereof.
That is, they claim that sampling strategies are systematically linked to decision strategies, and that the proposed links can explain the (non)occurrence of an as-if underweighting of rare outcomes pattern.
Yet, no formal and complete accounts of the potential choice-generating mechanisms---which must contain the proposed links---are offered.
Such a lack of mathematical and/or computational modeling can, among others, hide needed auxiliary assumptions and potential gaps and inconsistencies in the theory [@guestHowComputationalModeling2021; @vanrooijPsychologicalModelsTheir2022].
For instance, one key characteristic of the sampling paradigm is that people can freely decide when to stop sampling.
Thus, in order to be considered complete, models aiming to explain how the mind exercises the capacity of making DFE in the sampling paradigm must account for stopping.
However, theoretical frameworks and their model members that do so, e.g., sequential sampling models [e.g., @markantModelingChoiceSearch2015], make their own assumptions about the decision-making process that not only have implications for what choice data is expected, but may also constrain how the proposed link between sampling and decision strategies can plausibly be integrated in a given framework (see model specifications/implementations in this paper).
Assuming that "every scientific output is model- and theory-laden (i.e., contains theoretical and modeling commitments)" [@guestHowComputationalModeling2021, p. 5], not explicitly spelling out such commitments and/or formally modeling the respective decision-making process reduces (at least) the clarity of the theoretical claims and everything that follows in the scientific inference process.

2. *No systematic consideration of intermediate and hybrid models:*
In principal, the sampling and decision strategies, as proposed, can be combined without constraints---i.e., each instance of a sampling strategy can be combined with each instance of a decision strategy.
Moreover, the discussed sampling strategies (comprehensive and piecewise sampling) are considered paradigmatic not in the sense that people are expected to adopt either one or the other sampling strategy, but in the sense that they are the ends of a continuum and that many people are expected to adopt strategies that fall in between these two (see Fig.\ \@ref(fig:sampling-paradigm)).
Focusing only on the proposed links between sampling and decision strategies, the authors do not discuss the potential implications of either one of these points for the resulting choice patterns.
That is, the presented work does not systematically consider the potential interplay between sampling and decision strategies and its effects.
In defense, one might object that the decision strategies determine how the prospects are evaluated on the basis of the sampled outcomes, and thus, once a given decision strategy is adopted, the sampling strategy upfront has no more impact on the final choice.
In other words, sampling strategies may alter which decision strategies are used, but they do not alter how a given decision strategy evaluates a prospect.
But this would be a superficial and vulnerable argument for reasons that become obvious when trying to specify or implement a plausible model of the decision-making process.
For instance, if people do not exactly follow the piecewise sampling strategy, one might still be willing to allow for the adoption of a round-wise decision strategy and, in order to make this go through, assume that a comparison-round may encompass more than one outcome sampled from each prospect.
In this case, however, sampling strategies can have a severe impact on the evaluation of prospects because they alter the size of the samples that a round encompasses (see analyses in this paper).
One may otherwise waive the assumption that a comparison-round encompasses more than one outcome per prospect, but this can cause the decision-making process to take a form that is fundamentally different from how it might have been perceived---at least implicitly according to unstated theoretical commitments---when only the paradigmatic instances were considered.
In sum, to understand whether and how sampling and decision strategies act together to shape DFE, one should not only explicitly model their links, but also consider their interplay broadly and systematically.

3. *Use of heuristic analysis methods:*
The empirical re-analysis relies on various heuristic methods to assess whether the observed choices are consistent with the claimed links between sampling and decision strategies and their impact on the as-if weighting of rare events pattern.
For instance, aggregated data over participants and choice problems is used to compare, within and between sampling strategies, the proportions of choices that are consistent with the predictions of the decision strategies and an as-if underweighting of rare outcomes.
In addition, to obtain indicators for the applied sampling strategies, each participant's mean switching frequency across all choice problems was calculated and a median split was used to identify infrequently and frequently switching people, supposedly indicating comprehensive and piecewise sampling, respectively.
While acknowledging that existing data was used, such heuristic methods can be problematic, e.g., because they can cause a construct-behavior gap where inferences from the data to the tested theory, although statistically sound, become logically invalid.
In a rigorous analysis, @regenwetterConstructbehaviorGapBehavioral2017 demonstrate how the use of aggregated data and heuristic scoring rules, e.g., counting the proportion of correct choice predictions across problems and people, lead at least to hard-to-interpret inferences about individuals' as-if weighting patterns and the description-experience gap.
One can alleviate such risks by taking heterogeneity between individuals into account and modeling the as-if weighting more explicitly.
Also, the averaging of switching frequencies across choice problems to group into frequent and infrequent switchers can be falsely interpreted as if sampling strategies are more a characteristic of the decision maker than of the sampling process.
Finally, sampling error is only controlled for to the extent that choice trials in which small-probability outcomes were not sampled at least once are excluded from the analyses.
This still leaves room for the sampled relative frequencies to deviate from the latent objective probabilities.

4. *No discussion of choice problems:*
Assuming representative sampled frequencies, summary and round-wise decisions only predict different choices, if the prospect with the larger EV is not also more likely to produce a higher outcome most of the time (see Fig.\ \@ref(fig:sampling-paradigm)).
In consequence, the structure of the choice problems---i.e, whether a small-probability outcome exists and how desirable it is---can quite dramatically shape how the (interplay of) strategies differ in the choices and as-if weighting patterns they produce.
Focusing only on problems of such a structure may provide a parsimonious but narrow-in-scope interpretation. 

The current paper aims to extend the work of @hillsInformationSearchDecisions2010 and to address the outlined problems.
The rest of the paper is structured as follows:
In the first section, the current approach and its theoretical commitments are briefly outlined.
The paper starts from the proposition that systematic choices in DFE must be based on the assessment of differences in the latent properties of prospects (e.g., differences in EV or differences in the probability to produce a higher outcome most of the time).
Sequential sampling models of decision making are considered as a theoretical framework that can be used to explain how the mind samples and accumulates evidence about such differences over time, and---importantly---how the mind stops sampling once an evidence threshold is reached.
In the section that follows, two models are specified, each of which integrates the continuum of sampling strategies and one of the proposed decision strategies into the computational framework of sequential sampling models.
The expected behaviors of the models are outlined.
Thereafter, a simulation study is presented, where the proposed models are used to simulate the sampling and accumulation processes for a set of choices between a safe and a two-outcome prospect, the latter of which may or may not possess a small-probability outcome of different rank/desirability.
Controlling for sampling error---i.e., considering the sampled relative frequencies rather than the latent objective probabilities---, this paper then seeks to investigate in a computational analysis whether and how the potential interplay of sampling and decision strategies shapes DFE and comes to imply choice patterns and functional forms of cumulative prospect theory [CPT, @tverskyAdvancesProspectTheory1992] that are consistent with an as-if underweighting of rare outcomes pattern.^[<!--Open footnote-->
CPT's value function is also considered in this paper.
However, the focus is on the weighting function, as it is commonly used to describe an as-if overweighting and underweighting of rare outcomes, and the description-experience gap [see, e.g., @kellenHowVariantAre2016; @regenwetterConstructbehaviorGapBehavioral2017; but see @hertwigConstructbehaviorGapDescription2018].
<!--Close footnote-->]
It is shown that within a sequential sampling framework, the interplay of sampling and decision strategies produces systematically different choice patterns that depend on the structure of the choice problems and translate to distinct signatures in CPT's weighting and value function.
The simulated choices and estimated CPT parameters can be understood as model-implied data and data models, which remain to be tested against empirical data.
The paper closes with a brief discussion and conclusion.
Note that all materials---i.e., code and data---underlying this paper can be retrieved from the accompanying `GitHub` repository.

# Sampling and Decision Strategies Within a Sequential Sampling Framework

Because there is an uncountable number of decisions people confront in their daily life, behavioral decision research routinely abstracts from choices between particular alternatives, e.g., the choice between job offers, political parties to vote for, or investment plans.
Rather, with the choice between at least two prospects, it studies a case which is counterfactual in that it omits the many particularities of each choice situation but retains in the form of prospects the fundamental properties that almost all choice alternatives are assumed to possess.
These fundamental properties are considered the $n$ possible outcomes of a choice alternative, denoted as $x_1, ..., x_n$, and the probabilities with which these outcomes occur following the choice of the alternative, denoted as $p_X(x_1), ..., p_X(x_n)$. 
That is, each choice alternative that is fully described by a set of outcome-probability pairs, $\{(x_i, p_X(x_i))\}_{i \in \{1, ..., n\}}$, satisfying $\sum_{i = 1}^n p_X(x_i) = 1$, is a prospect.
It is only through these fundamental properties, or combinations thereof, that any necessary distinction between the prospects can be made.
Hence, systematic---as opposed to random---choices between prospects must be based on the assessment of differences in their properties.

Rarely in peoples' daily life, does the information provided about the prospects take the form of explicit and complete descriptions of all their outcome-probability pairs.
In such rare cases, people would make DFD and can---strongly simplified---directly proceed by selecting a property or combinations thereof to assess differences among the prospects and make a respective choice.
In stark contrast and rather often, people are required to make DFE, where the mind can learn about the latent properties only by "experiential sampling [of outcomes] over time" [@hertwigDescriptionexperienceGapRisky2009, p. 517, square bracket added].
The sampling paradigm is just one paradigm that can be used to study DFE experimentally and allows people to sample the prospects' outcomes without costs and without constraints regarding the sequential pattern and the amount of sampled outcomes.

How do people arrive at a final choice in the sampling paradigm? 
Sequential sampling models of decision making under risk (DFD) and/or uncertainty [DFE, see @markantModelingChoiceSearch2015, who explicitly consider DFE and the sampling paradigm; see also, e.g., @bhatiaSequentialSamplingParadoxes2014; @busemeyerDecisionFieldTheory1993] assume that the decision-making process takes the form of an accumulation of evidence for the prospects over time.
The process is assumed to stop---i.e., a choice is made---once the accumulated evidence for one of the prospects reaches an evidence threshold.
More specifically, for DFE, it is assumed that the outcomes of prospects are sequentially sampled and integrated into dynamic decision variables and that a choice is made once the value of a decision variable exceeds a threshold.
How exactly this integration is carried out and what the value of a dynamic decision variable represents, is a theoretical question---and thus a matter of the exact specification of the model---largely concerned with the way the prospects are assumed to be evaluated.
Depending on the integration and evaluation mechanisms they assume, the member models of the sequential sampling framework have been shown to explain some of the robust deviations from EV maximization, including the as-if underweighting of rare outcomes in the sampling paradigm [@markantModelingChoiceSearch2015].
Moreover, these models implement speed-accuracy trade-offs, with the amount of evidence that must be sampled in favor of a prospect increasing with thresholds, leading to more accurate but slower choices for high thresholds, and vice versa.

The current paper commits to the core assumptions of the sequential sampling framework and uses its flexibility regarding the exact mechanisms of sampling, integration, and evaluation to incorporate the idea of sampling and decision strategies, including their interplay.
The two models presented below, one assuming an integration and evaluation mechanism resembling the round-wise strategy, the other assuming mechanisms resembling the summary strategy, offer a formal route to explore the potential interplay between sampling and integration/decision strategies, and their effects on the choice behavior.
The sequential sampling framework is chosen as a modeling outlet not only because it makes parsimonious assumptions about the decision-making process and accounts for the behavior in various decision-making tasks [@ratcliffComparisonSequentialSampling2004], but primarily because it makes---taking a Marrian perspective [cf. @marrVisionComputationalInvestigation1982; @marrUnderstandingComputationUnderstanding1977; see also, e.g., @griffithsProbabilisticModelsCognition2010]---explicit a core part of the computational problem the mind is trying to solve in DFE, and the principle logic that governs the solution:
In order to make systematic choices between prospects, the mind must assess true differences in their *latent* properties, and it can only do so by searching for evidence for such differences in information samples.
Sequential sampling models of DFE make this clear by assuming an evidence accumulation process over sampled outcomes that is more or less directed towards particular latent properties.
Round-wise and summary decisions are both indicative for distinct latent properties, i.e., the expected value and the probability to produce a higher outcome most of the time, respectively.
The remainder of the paper discusses and demonstrates in a simulation, how integration/decision strategies can act together with sampling strategies and evidence thresholds to alter the degree and the accuracy with which differences about either one of these properties are assessed.

# Models 

Let us consider the sampling paradigm and a choice between two prospects, $P^X$ and $P^Y$.
Let $P^X$ be a probability---or pushforward---measure assigning to each possible outcome $x$ of the random variable $X$ a probability $p_X(x)$.
$P^Y$ is defined in a similar way.
Graphical sketches of the round-wise and summary integration model are displayed in Figure\ \@ref(fig:models).

\begin{figure}[t!]
\caption{Integration of Sampling and Integration/Decision Strategies into a Sequential Sampling Model}
\includegraphics{manuscript_files/models} \label{fig:models}
\raggedright \textit{Note.} In both models, to arrive at a final choice, it is assumed that outcomes from two prospects (here: violet vs. orange, see Fig.~\ref{fig:sampling-paradigm}, for details), are sequentially sampled and integrated
into dynamic decision variables until one of the variables reaches a threshold (not displayed). Round-wise integration model: The value of the decision variable is the cumulative sum of won mean comparisons. Each mean comparison encompasses the outcomes that were sampled from the same prospect in direct succession (without a switch in between). The thresholds govern the required (difference in the) number of won comparisons. Summary integration: The value of the decision variable is the cumulative sum across all outcomes sampled from a prospect. The thresholds govern the required (difference in the) cumulative sums. Both integration models allow for differences in thresholds and switching probabilities.  
\end{figure}

## Round-Wise Integration Model

The model assumes that the sampling process starts at random with a stochastic process on one of the two prospects.
Specifically, it is assumed that an agent starts with equal probability to sample from one of the prospects, say $P^X$, and generates a sequence of sampled outcomes, denoted by the random variables $X_1, X_2,...$, where the mean over this sequence is computed or updated with each new sampled outcome.
The respective stochastic process $\{S^X_t\}_{t \in \mathbb{N}}$ is defined by
$$
S^X_t = \frac{1}{t} \sum_{k = 1}^t X_k, \quad k \in \mathbb{N}
\; ,
\tag{1}
$$
where $S^X_t$ is the mean across $t$ outcomes that were *successively* sampled from prospect $P^X$.
Each such stochastic process terminates as soon as an outcome is sampled from the other prospect, i.e., the stochastic process on prospect $P^X$ stops as soon as an outcome is sampled from prospect $P^Y$, and vice versa.
The switching probability $\psi \in (0,1]$, which is assumed to be adopted prior the start of the sampling and accumulation process, is fixed throughout and controls the probability with which outcomes from different prospects are sampled in direct succession.
In other words, the switching probability $\psi$ governs the probability with which the stochastic process on a given prospect, defined as in (1), stops and a new stochastic process on the other prospect starts with the subsequently sampled outcome.

To implement the evidence accumulation process, the round-wise integration model assumes that each time a *new* stochastic process gets started and then terminated on both prospects, their respective means are compared, with the prospect underlying the stochastic process with the greater mean receiving a round win.
Accordingly, assuming that $S^Y_m$ is the mean across $m$ outcomes successively sampled from prospect $P^Y$, this stage is modeled for the prospect $P^X$as the mapping
$$
\begin{aligned}
  Z^X : \mathbb{R} &\to \mathbb{N} \\
  S^X_t - S^Y_m &\mapsto 
  \begin{cases}
     1 &\text{if} \qquad  S^X_t > S^Y_m, \\
     0 &\text{else}
     \; ,
  \end{cases}
\end{aligned}
\tag{2}
$$
where $Z^X$ is a random variable that takes only the two values $0$ and $1$, denoting a lost or won mean comparison, respectively.
Let us denote the steps defined in (1) and (2) as a round of mean comparison (short: *comparison round*, see Fig.\ \@ref(fig:models)).

The model assumes that such comparison rounds are repeatedly carried out until the cumulative sum of round wins for one of the two prospects reaches a threshold $\theta \in \mathbb{N}$.
Similar to the switching probability, it is assumed that the threshold $\theta$ is adopted prior the start of the sampling and accumulation process and is fixed throughout.
For $P^X$, then, one obtains a sequence of mean comparisons, denoted as $Z^X_1, Z^X_2, ...$, and an evidence accumulation process taking the form of a random walk $\{D^X_v\}_{v \in \mathbb{N}}$ defined by
$$
D^X_v = \sum_{c = 1}^v Z^X_c, \quad c \in \mathbb{N}
\;.
\tag{3}
$$
$D^X_v$ is the cumulative sum of round wins of prospect $P^X$ after $v$ comparison rounds, and resembles a dynamic decision variable.
Note that since (2) describes a Bernoulli trial, the random walk in (3) is based on a Bernoulli process.
Prospect $P^X$ would be chosen once $D^Y_v < \theta \leq D^X_v$ is satisfied, and vice versa.

Finally, note that the described model assumes two random walks---i.e., one for each prospect---approaching the same threshold, which is the absolute number of mean comparisons a prospect must win in order to be chosen.
However, one may also define a single random walk, resembling a common dynamic decision variable, which approaches a positive threshold $\theta^+$ and a negative threshold $\theta^-$.
That is, (2) may be adapted such that $Z$ takes the value $-1$ instead of $0$, such that the threshold determines how many more mean comparisons a prospect must win in order to be chosen.

## Summary Integration Model

The model assumes that an agent starts with equal probability to sample outcomes from one of the prospects and continues sampling while switching between prospects according to the switching probability $\psi$.
As in the round-wise integration model, the switching probability $\psi$ is assumed to be adopted prior to the start of the sampling and accumulation process and is fixed throughout.

To implement the evidence accumulation process, the summary integration model assumes that an agent continues sampling from both prospects until the cumulative sum across all outcomes sampled from one of the prospects reaches a threshold $\theta$. 
As in the round-wise integration model, the threshold $\theta$ is assumed to be adopted prior the start of the sampling and accumulation process and is fixed throughout.
For $P^X$, then, one obtains a sequence of sampled outcomes, $X_1, X_2, ...$, and an evidence accumulation process taking the form of a random walk $\{D^X_t\}_{t \in \mathbb{N}}$ defined by 
$$
D^X_t = \sum_{k = 1}^t X_k, \quad k \in \mathbb{N}
\; ,
\tag{4}
$$
where $D^X_t$ is the cumulative sum across $t$ outcomes sampled from prospect $P^X$ and resembles a dynamic decision variable.
Assuming that $D^Y_m$ is the cumulative sum across $m$ sampled outcomes from prospect $P^Y$, prospect $P^X$ would be chosen once $D^Y_m < \theta \leq D^X_t$ is satisfied, and vice versa.

Note again that the described model assumes two random walks---i.e., one for each prospect---approaching the same threshold, which now is the cumulative sum across all sampled outcomes a prospect must produce in order to be chosen.
However, one may also define a single random walk, resembling a common dynamic decision variable, which approaches a positive threshold $\theta^+$ and a negative threshold $\theta^-$.
That is, (4) may be substituted by
$$
D^X_{t,m} = \sum_{k = 1}^t X_k - \sum_{j = 1}^m Y_j \quad k,j \in \mathbb{N}
\; ,
\tag{5}
$$
where $D^X_{t,m}$ is the difference between the cumulative sums across $t$ and $m$ outcomes sampled from prospects $P^X$ and $P^Y$, respectively.
The thresholds thus determine how much larger the cumulative sum of a prospect must be in order for the prospect to be chosen.

# What Model Behaviors Are Expected?

Below, it is discussed which effects the key model parameters, i.e., the switching probability $\psi$ and the threshold $\theta$, could have on the choices and the corresponding as-if weighting patterns that are implied by the round-wise and the summary integration model.
The effects of the switching probability should be informative about the interplay between different sampling strategies and the integration/decision strategy each model resembles.
Assuming that both models aim to assess true differences in the latent properties of prospects, the effects of the threshold should indicate whether these differences are indeed more accurately assessed---thus, leading to more systematic choices and as-if weighting patterns---the more evidence is accumulated.
In addition, previous research has shown that differences as to how information about the properties of prospects is processed can translate to distinct signatures in CPT's psychoeconomic value and weighting function, without actually assuming that these functions are computed whatsoever [see @pachurHowTwainCan2017; @stewartDecisionSampling2006; @zilkerNonlinearProbabilityWeighting2021].^[<!--Open footnote-->
Note that it has been argued that the distinction between CPT's functions used to describe choice data and models aiming to explain how this data is generated in the first place are reminiscent of Marr's [-@marrVisionComputationalInvestigation1982] different levels of explanation [@zilkerMeasuringModelingConstruction2020; also cf. @griffithsProbabilisticModelsCognition2010].
That is, whereas CPT may be considered a computational-level theory that describes an abstract solution to the problem the mind aims to solve when offered a choice between prospects, process models [cf. @jareckiFrameworkBuildingCognitive2020], such as heuristics and sequential sampling models, may be considered algorithmic-level theories that specify how the mind can approximate the abstract solution with the capacity limits it is constrained by.
<!--Close footnote-->]
Accordingly, this section also formulates expectations regarding the potential relations between switching probabilities and thresholds (data-generating parameters) and the CPT parameters (data-modeling parameters).

## Potential Impact on Final Choices

The discussion below is constrained to choices between prospects that possess only positive outcomes. 
Summaries of the expected model behaviors can be found in Tables\ \@ref(tab:expectations-roundwise) and \@ref(tab:expectations-summary).

### Round-Wise Integration Model

Considering a *single* comparison round, the stochastic process for each prospect---which results in a mean computed across the outcomes sampled from the prospect---is predicted to terminate faster, the higher the probability that the subsequent outcome is sampled from the other prospect, i.e., the higher the switching probability $\psi$.
Because the switching probability is predicted to alter the length of the stochastic processes underlying *each independent* mean comparison, it should affect whether low-probability outcomes contribute to each required mean comparison about as much as would be warranted based on their objective probabilities, or whether they contribute rather less.
That is, for high switching probabilities and thus, short stochastic processes, the binomial distribution associated with small-probability outcomes is positively skewed, causing the relative frequencies with which these outcomes occur within each comparison round to be smaller rather than larger than their latent objective probabilities.
Because such a distortion of the relative sampled frequencies from the objective probabilities is expected for each comparison round, increases in the threshold $\theta$ should not affect the following expectations concerning the model behavior; rather because each comparison is independent and increases in sample size (here: number of comparisons) reduce random error, the expectations should be more accurately met for higher thresholds:
If the small-probability outcome is smaller (larger) than the EV, high switching probabilities cause the mean within each comparison round to be an inflated (deflated) estimate of the EV.
Such an inflation and deflation of the means within each round can then translate to choices that take the form of an as-if underweighting of rare outcomes:
Specifically, if the means of the prospect with the lower (higher) EV are inflated (deflated), the outcomes of each mean comparison may be a reversal---in sign---of the outcome of a comparison between the EVs, eventually translating to choices resembling an as-if underweighting of rare outcomes.
Yet, if the means of the prospect with the lower (higher) EV are deflated (inflated), the difference between the means should be larger than the differences between the EV, which can simplify EV maximization [see @hertwigDecisionsExperienceWhy2010].
In contrast, for low values of the switching probability $\psi$---and therefore pairs of long stochastic processes---the means in each round should closely correspond to the EVs, leading to choices that are in line with EV maximization.

Note that the entire line of reasoning from above should also apply, if sampling error is controlled for.
That is, if the EVs are substituted by the means across all outcomes sampled from a prospect over the course of the entire sampling and accumulation process, the means within each comparison round are still expected to deviate from this sampling error-encompassing substitute in the manner outlined above.
Moreover, because the mean across the entire sampling and accumulation process is expected to converge to the EV the more outcomes are sampled overall, the choice patterns with and without sampling error should resemble each other more closely, the higher the thresholds get.

To summarize the choice predictions and simplify: 
If the prospect that is more likely to return a higher outcome most of the time does not also possess the higher EV or mean across all outcomes sampled over the course of a sampling and accumulation process, high switching probabilities are predicted to cause an as-if underweighting of rare outcomes pattern.
For low switching probabilities, choices are expected to maximize the EV or mean across all sampled outcomes.
Hence, in the round-wise integration model, the switching probability is expected to alter the degree and thus, also the accuracy with which differences among prospects are assessed in either one of these latent properties: the expected value or the probability to produce a higher outcome most of the time.
These expectations concerning the model behavior should be more accurately met, the larger the thresholds $\theta$.

### Summary Integration Model

First, note that the summary integration model differs from the summary strategy proposed by Hills and Hertwig [-@hillsInformationSearchDecisions2010] to the extent that cumulative sums rather than means are calculated across all outcomes sampled from a prospect.^[<!--Open footnote-->
I.e., one must ensure that the summary statistic in fact approaches and reaches a threshold in order for the code to not run endlessly.
Note that this is not a mere technical issue, but implied by the theoretical assumptions of the sequential sampling framework.
<!--Close footnote-->] 
This could introduce interactions between switching probabilities and thresholds that are not implied by a model that assumes comparisons between means.

Because the required (difference in) cumulative sums across all outcomes sampled from each prospect increases with thresholds $\theta$, the number of outcomes that is required to be sampled to reach the thresholds should increase accordingly.
Hence, in principle, the larger the thresholds, the more should small-probability outcomes contribute to the cumulative sum as much as would be warranted by their objective probabilities.
Accordingly, one might expect that the implied choices generally maximize the overall sampled mean and converge to the solutions of EV maximization, the larger the thresholds get.
However, the switching probabilities should introduce temporal imbalances between prospects regarding the number of sampled outcomes over which the sums are computed (and compared, assuming relative thresholds, respectively).
That is, whatever prospect is first sampled from is allowed to start accumulating evidence sooner than the respective other prospect.
This is likely to be a negligible factor for large but not for small switching probabilities.
Specifically, the temporal imbalances---i.e., the temporal advantage for the prospect which is sampled from first---grows as the switching probabilities decrease.
Accordingly, for small switching probabilities, choices might be largely driven by the truly random event which prospect is first sampled from.
This random choice behavior should diminish with increases in the switching probability and choices should converge to the solutions of sampled mean and EV maximization the higher the thresholds get.

Taking together the expected effects for thresholds and switching probabilities, the expectations for the choices implied by the summary integration model are summarized as follows:
For small switching probabilities, choice behavior should be more or less random.
With increasing switching probabilities, choice behavior should become more systematic and driven by differences in the thresholds:
For small thresholds, an as-if underweighting of rare outcomes pattern is expected to occur because small-probability outcomes should be systematically underrepresented due to their skewed binomial distribution.
This pattern should be (fully) alleviated, if sampling error is taken into account.
For large thresholds, choices should converge more to the solutions of EV maximization, even more so to the solutions of sampled mean maximization (i.e., when sampling error is accounted for).

## Cumulative Prospect Theory

Before elaborating on how the expectations outlined above may translate into estimates of the CPT parameters, the following section reviews how CPT in general and its weighting function in particular capture deviations from EV maximization.

### Description of CPT

The actual choices people make between prospects are often *described* in terms of deviations from EV maximization, according to which the prospect with the largest EV
$$
EV = \sum_{i \in \mathbb{N}}^n x_i \times p_X(x_i)
\tag{6}
$$ 
should be chosen.
To describe how people's choices deviate from EV maximization [see @erevAnomaliesForecastsDescriptive2017, for a recent replication of classical demonstrations; see also @kahnemanProspectTheoryAnalysis1979; @tverskyAdvancesProspectTheory1992], CPT and similar rank-dependent models [see @stottCumulativeProspectTheory2006, for an overview of models] fit choice data by assuming that people maximize the valuation
$$
V = \sum_{i \in \mathbb{N}}^n v(x_i) \times \pi_i
\; ,
\tag{7}
$$ 
with objective outcomes $x_i$ being transformed by a value function $v$, and *cumulative decision weights* $\pi_i$ being determined by the difference between transformed cumulative probabilities of the distribution $P$.
More specifically, following @tverskyAdvancesProspectTheory1992, the objective outcomes are transformed by a value function
$$
\begin{aligned}
  v : \Omega' &\to \mathbb{R} \\
  x &\mapsto 
  \begin{cases}
     x_i^\alpha &\forall x_i \geq 0, \\
     -\lambda |x_i|^\alpha &\text{else}
     \; ,
  \end{cases}
\end{aligned}
\tag{8}
$$
with $\alpha \in [0,1]$ determining the degree of the function's concavity (convexity) over the positive (negative) outcome interval, and $\lambda > 1$ increasing the function's slope over the negative outcome interval only.
Each subjective value $v(x)$ is then multiplied (or: weighted) with a cumulative decision weight that takes the form
$$
\pi_i =
  \begin{cases}
     w^+(P(X \geq x_i)) - w^+(P(X > x_i)) \quad \forall x_i \geq 0, \\
     w^-(P(X \leq x_i)) - w^-(P(X < x_i)) \quad \text{else}
     \; , 
  \end{cases}
\tag{9}
$$
where $w$ is a monotonic increasing, nonlinear weighting function satisfying $w^+(0) = w^-(0) = 0$ and $w^+(1) = w^-(1) = 1$.
To simplify matters, the further discussion of CPT and the computational analysis are constrained to choices between a safe prospect---possessing just one outcome that occurs with certainty---and a two-outcome prospect (hereafter: risky prospect).
All outcomes are assumed to be positive and the safe outcome is assumed to fall between the the low-rank outcome, $x_{low}$, and the high-rank outcome, $x_{high}$, of the risky prospect to omit dominance.
One can then disregard the negative parts of (8) and (9), including the parameter $\lambda$ of the value function, and (9) simplifies to
$$
\begin{aligned}
  \pi_{high} &= w(p_x(x_{high})) \\
  \pi_{low} &= w(p_x(x_{low}) + p_x(x_{high})) - w(p_x(x_{high})) \\
  &= 1 - \pi_{high}
  \; .
\end{aligned}
\tag{10}
$$

Essentially, the model is such that the cumulative decision weights derived for the outcomes of the risky prospect may be greater or smaller than their objective probabilities, causing the transformed outcomes---i.e., the subjective values---to be over- or underweighted *within* CPT, respectively.
Accordingly, for the description of choices, one may adopt an as-if weighting terminology by stating that people choose as if they maximized the value in (7) and applied the weighting pattern that was estimated in CPT.
Importantly, the as-if prefix indicates that there is no claim that the mind indeed performs any of the computations associated with the weighting of subjective values; 
rather, the mind processes the information about the properties of choice alternatives in a way that the resulting choices translate to the estimated weighting pattern [cf. @gigerenzerHowExplainBehavior2020].
Accordingly, once again, this paper treats CPT as a data model and discusses---and refines in a simulation---what weighting patterns can be expected, were the mind to carry out the sampling and accumulation processes that are assumed by the presented round-wise and summary integration model [see @pachurHowTwainCan2017; @zilkerNonlinearProbabilityWeighting2021, for similar theoretical inquiries].

Now, several consequences for the weighting patterns that can be estimated in CPT follow from the exact specification of the weighting function $w$, which are briefly reviewed next. Figure\ \@ref(fig:weighting-function) illustrates some of the possible graphical shapes of the two-parameter weighting function of @goldsteinExpressionTheoryPreference1987, which, however, is just one of several parameterizations that have been proposed [e.g., @prelecProbabilityWeightingFunction1998; @tverskyAdvancesProspectTheory1992; see @stottCumulativeProspectTheory2006, for an overview].
Each graph in Figure\ \@ref(fig:weighting-function) displays the graphical shape of the weighting function
$$
\begin{aligned}
  w : [0,1] &\to [0,1] \\
  p_X(x_{high}) &\mapsto \frac{\delta \times (p_X(x_{high}))^{\gamma}}
  {\delta \times (p_X(x_{high}))^{\gamma} + (1-p_X(x_{high}))^{\gamma}}
  \; ,
\end{aligned}
\tag{11}
$$
for the respective values of the parameters $\gamma \in [0,2]$ and $\delta > 0$.
Evidently from the figure, both parameters have distinct effects on the graphs' shape, with $\gamma$ affecting the curvature and $\delta$ the elevation.
As a consequence from (10) and (11), each combination of parameters implies a particular weighting pattern that amounts to either a linear or an over- and underweighting of the high-rank outcome of the risky prospect, depending on its probability.
Hence, for the considered case---choices between a safe and a two-outcome risky prospect---, the estimated weighting function can be directly interpreted in terms of an as-if over- or underweighting of small-probability outcomes. 

```{r weighting-function, include=FALSE}
#compute images of weighting function (wf)
wf <- tibble(p = seq(0, 1, .01)) %>%  #cumulative probabilities
  expand_grid(gamma = seq(.1, 2, .1), #gamma values
              delta = c(.1, .5, 1, 2, 5, 10)) %>% #delta values
  mutate(wp = (delta*(p^gamma))/((delta*p^gamma)+(1-p)^gamma)) #images of wf

#labeller function for facet labels with LateX math expressions 
label_delta <- function(string) {
  TeX(paste("$\\delta=$", string, sep = ""))  
}

#plot shapes of weighting function
wf %>% 
  ggplot(aes(p, wp, group = gamma)) +
  facet_wrap(~delta, labeller = as_labeller(label_delta, default = label_parsed)) + 
  scale_x_continuous(breaks = seq(0, 1, .5)) +
  scale_y_continuous(breaks = seq(0, 1, .5)) + 
  labs(x = "Probability of High-Rank Risky Outcome",
       y = "Transformed Probability (Decision Weight)", 
       color = expression(gamma)) + 
  theme_minimal() + 
  geom_line(aes(color = gamma), size = .5) +
  scale_color_viridis(option = "inferno") + 
  geom_abline(intercept = 0, slope = 1, color = "gray", linetype = "dashed")
```

\begin{figure}[t!]
\caption{Possible Graphical Shapes of Goldstein and Einhorn's (\protect\hyperlink{ref-goldsteinExpressionTheoryPreference1987}{1987}) Weighting Function}
\includegraphics{manuscript_files/figure-latex/weighting-function-1} \label{fig:weighting-function}
\raggedright \textit{Note.} The gray-dashed identity lines indicate a linear weighting pattern, implied by \(\gamma = 1\) and \(\delta = 1\). Deviations produce a nonlinear graphical shape. \(\gamma\): For \(\gamma > 1\), graphs take a S-shape---running below (above) the identity line for small (large) probabilities---which is more accentuated for larger deviations from \(\gamma = 1\). Hence, decisions weights are smaller (larger) than the objective probabilities for small-probability (high-probability) outcomes. For \(\gamma < 1\), the graph of \(w\) takes an inverse S-shape and the weighting pattern reverses. \(\delta\): Shifts across the entire probability scale the intervals within which objective probabilities translate to either smaller or greater decision weights. For \(\delta < 1\), the interval over which the graph runs below the identity line is greater than the interval over which the graph runs above the identity line; the pattern reverses for \(\delta > 1\).
\end{figure}

### How Is CPT Expected to Reflect the Model-Implied Choices?

To begin with, as evident from Figure\ \@ref(fig:weighting-function), for $\gamma > 1$, the high-rank outcome of the risky prospect is underweighted (overweighted) in CPT, if it is of small (large) probability, and $\delta \neq 1$ shifts the range of the over- and underweighting.
In the following discussion, it is assumed that sampling error is controlled for. 
That is, for each sampling and accumulation process, the weighting function is supplied with the overall sampled relative frequencies (hereafter: sampled probability) rather than with the objective probabilities.  

#### Round-Wise Integration Model

Since for low values of the switching probability $\psi$ the model is expected to choose the prospect that produced the larger overall sample mean, the parameters of the value and weighting function should correspond to a linear weighting of outcomes and sampled probabilities, which is given for $\alpha = 1$, $\gamma = 1$, and $\delta = 1$.
However, for high switching probabilities, the model is expected to choose the risky prospect for $p_x(x_{high}) > .5$---i.e., if the latent probability of the higher risky prospect is $> .5$, the risky prospect is expected to produce the higher outcome most of the time---, irrespective of the differences in the overall sample mean.
Vice versa, the model tends to choose the safe outcome for $p_x(x_{high}) < .5$---i.e., the safe prospect is expected to produce the higher outcome most of the time.
Correspondingly, for high switching probabilities, the weighting pattern should be such that the high-rank outcome of the risky prospect is overweighted for sampled relative frequencies $> .5$, and underweighted otherwise.
Hence, for high switching probabilities, the graph of the weighting function should take a S-shape, which is given for $\gamma > 1$.
Because the over- and underweighting of the high-rank outcome is not expected to extend across the mid-point of the probability scale, $\delta$ should take values around 1.

Note that the graph of the weighting function that is expected for high switching probabilities would reflect the round-wise strategy's high sensitivity to differences in the latent probability to produce the higher outcome most of the time:
Specifically, the slope of the weighting function's graph would be most severe around the midpoint of the probability scale.
The predicted flat ends of the graph, however, indicate that the round-wise strategy more or less ignores how much larger than $.5$ the probability to produce a higher outcome is. 
In sum, then, $\delta$ is not expected to change with the switching probability.
However, $\gamma$ is expected to increase with the switching probability, thereby reflecting differences in the extent to which the prospect with the higher EV or with the probability to produce a higher outcome most of the time is chosen.
As for the choice patterns, the expectations should be more accurately met for high thresholds.

Moreover, because the model is such that the magnitudes of outcomes are ignored once a comparison is carried out, increases in the switching probability $\psi$ should lead to a more concave value function.
That is, the higher the switching probabilities, the more the choices depend on which prospect produces the higher outcome most of the time, irrespective of how much larger the outcomes are.
Respectively, $\alpha$ is predicted to decrease with increases in $\psi$.

(ref:expectations-roundwise) Expected Effects of Switching Probability $\psi$ and Threshold $\theta$ Implied by the Round-Wise Integration Model

```{r expectations-roundwise}
exp_roundwise <- tibble("Measure" = 
                        c("Choices pattern",
                          "",
                          "$\\gamma$ (curvature of $w$)",
                          "$\\delta$ (elevation of $w$)",
                          "$\\alpha$ (concavity of $v$)"),
                      "Predictions for changes in $\\psi$ and $\\theta$" = 
                        c("More maximization of sampled mean for decreasing $\\psi$",
                          "More as-if underweighting of rare outcomes for increasing $\\psi$",
                          "$\\geq 1$, increases with $\\psi$",
                          "1, no effect of $\\psi$",
                          "$\\leq 1$, decreases with increasing $\\psi$"))

apa_table(exp_roundwise, caption = "(ref:expectations-roundwise)", note = "Expectations should be more closely met for high values of $\\theta$. Expectations rely on the assumption that sampling error is controlled for. The weighting function is assumed to be supplied with sampled relative frequencies.", escape = FALSE)
```

#### Summary Integration Model

For small switching probabilities $\psi$, the model is expected to make random choices to some unknown degree.
The respective CPT parameter estimates would be hard to interpret (if at all).
In the computational analysis, a stochastic version of CPT is estimated to account for such random behavior using a choice sensitivity parameter (see equation (12) below).
Because the summary integration model chooses the prospect that produces the larger cumulative sum across all sampled outcomes, a linear weighting of outcomes and sampled probabilities is expected for high switching probabilities, i.e., $\alpha = 1$, $\gamma = 1$, and $\delta = 1$.
This is because for high switching probabilities, differences in the cumulative sum across all sampled outcomes should be indicative for differences in the sampled means.
If thresholds $\theta$ are low, however, even large switching probabilities might produce some random behavior because of the temporal advantage of the prospect that is first sampled from.

(ref:expectations-summary) Expected Effects of Switching Probability $\psi$ and Threshold $\theta$ Implied by the Summary Integration Model

```{r expectations-summary}
exp_summary <- tibble("Measure" = 
                        c("Choices pattern",
                          "",
                          "$\\gamma$ (curvature of $w$)",
                          "$\\delta$ (elevation of $w$)",
                          "$\\alpha$ (concavity of $v$)"),
                      "Predictions for changes in $\\psi$ and $\\theta$" = 
                        c("Random for low $\\psi$",
                          "More Maximization of sampled mean for high $\\psi$ and $\\theta$",
                          "",
                          "1 for high $\\psi$ and $\\theta$, otherwise ?",
                          ""))

apa_table(exp_summary, caption = "(ref:expectations-summary)", note = "Expectations rely on the assumption that sampling error is controlled for. The weighting function is assumed to be supplied with sampled relative frequencies.", escape = FALSE)
```

# Simulation Study

To substantiate the above discussion and obtain the actual predictions of the models, computational implementations thereof were used to simulate the sampling and accumulation process for a set of choices between a safe prospect and a two-outcome (risky) prospect.
The computational models were written in `R` and are embodied in the `GitHub` repository accompanying this paper.
The simulation was conducted for varying combinations of the switching probability $\psi$ and threshold $\theta$.
For each of these combinations, the simulated data was modeled with a stochastic version of CPT, using Bayesian parameter estimation.
The simulated data and estimated CPT parameters can be understood as theory-implied data and data models which remain to be tested against empirical data.

## Method

Below, the simulation and modeling procedure is briefly described.

### Choice Problems

A test set of 60 choice problems was obtained by stratified sampling from an initial set of 10,000 problems.
The stratification procedure was used to ensure that the test set contained choice problems with small-probability outcomes of different rank---i.e., small-probability outcomes that are either higher or lower than the EV of the risky prospect---as well as choice problems without small-probability outcomes.
The exact procedure was as follows:
For each of the 10,000 problems in the initial set, three outcomes were randomly drawn from a uniform distribution over the interval $[0, 20]$, with the smallest and highest of these three outcomes being assigned to the risky prospect to omit dominance.^[<!--Open footnote-->I.e., where one prospect always produces a higher outcome.<!--Close footnote-->]
The probability for the lower outcome of the risky prospect, $p_x(x_{low})$, was drawn from a uniform distribution over the interval $(0, 1)$, with the probability of the higher outcome being set to $p_x(x_{high}) = 1-p_x(x_{low})$.
To obtain the 60 choice problems of the test set, the initial set was divided into three subsets, where each subset contained either all problems with $p_x(x_{high}) \in (0,.2)$ or $p_x(x_{high}) \in [.2,.8]$ or $p_x(x_{high}) \in (.8,1)$.
From each of these subsets, then, $20$ choice problems were randomly sampled.

### Data Generation

To simulate the sampling and accumulation processes, the following parameter values were used and combined with each other.
That is, each parameter combination was used to solve the test set.

* *Switching probability*: 
$\psi$ was varied in the interval $[.1, 1]$ in increments of $.1$.

* *Threshold*: 
Round-wise integration model: $\theta$ was varied in the interval $[1,5]$ in increments of 1. Summary integration model: $\theta$ was varied in the interval $[15, 75]$ in increments of 15.

* *Decision variable*: Round-wise integration model: The decision variable of a prospect either counts the number of won comparisons---implying an absolute threshold---or how many more or less comparisons were won relative to the other prospect---implying a relative threshold. Summary integration model: The decision variable of a prospect is either the cumulative sum across all sampled outcomes or the difference in cumulative sums, implying absolute and relative thresholds.^[<!--Open footnote-->
For both models, the results are similar for absolute and relative thresholds.
For simplification, only the results of the absolute thresholds are reported in the main text.
The results for relative thresholds are reported in the Appendix.
<!--Close footnote-->]

```{r subset-absolute, include=FALSE}
choices_absolute <- choices %>% filter(boundary == "absolute")
cpt_absolute <- cpt %>% filter(boundary == "absolute")
```

\noindent
Since the switching probability $\psi$ introduces some stochasticity into the sampling and accumulation process, each of the 100 resulting parameter combinations was used 100 times---resembling 100 independent agents---to solve the test set. 
In sum, then 2 (models) $\times$ 100 (parameter combinations) $\times$ 100 (agents) $\times$ 60 (choice problems)  = 1,200,000 sampling and accumulation processes were simulated.
The respective datasets can be both recreated or directly retrieved from the accompanying `GitHub` repository.

### Estimation of Stochastic CPT

The choice data implied by each integration model and parameter combination was separately modeled in CPT, using the value function of @tverskyAdvancesProspectTheory1992 and the weighting function of @goldsteinExpressionTheoryPreference1987.
Again, to demonstrate that the distortions from linear probability weighting are not just due to sampling error, the relative frequencies with which the outcomes were actually sampled over the course of a sampling and accumulation process were supplied as probability information to the weighting function.
To accommodate for possible random choice behavior that may be exerted by a parameter combination, the CPT model was amended with the logit choice rule
$$
p(P^{safe}) = \frac{1} {1 + e^{-\rho(V_{safe}^{\frac{1}{\alpha}}-V_{risky}^{\frac{1}{\alpha}})}}
\; ,
\tag{12}
$$
where $p(P^{safe})$ is the probability that the safe prospect is chosen over the risky prospect, $V_{safe}$ and $V_{risky}$ are the valuations of the safe and risky prospect that result from the parameter estimates of the value and weighting function, and $\rho \geq 0$ is a sensitivity parameter.
$\rho$ governs how strongly the choices between prospects depend on the differences in the valuations of the prospects, i.e., the core CPT model.
Specifically, $\rho = 0$ implies no sensitivity, and thus a completely random choice.
In turn, for increasing values of $\rho$, the probability of choosing the prospect with the higher valuation increases.
Note further that the valuation of the prospects were rescaled by $\frac{1}{\alpha}$, as proposed by @stewartPsychologicalParametersHave2018, to guard against possible parameter interdependencies between $\alpha$ and $\rho$ [@krefeld-schwalbStructuralParameterInterdependencies2022; @scheibehenneUsingBayesianHierarchical2015].
In sum, then, the model has four free parameters: $\alpha, \gamma, \delta, \rho$.

Since for a given choice problem and parameter combination of the sampling and accumulation model there should be no systematic differences among the 100 iterations (synthetic agents), their data is combined for the estimation of the free parameters.
Such a grouped approach should reveal the main effects of a given parameter combination of the sampling and accumulation model on the resulting choices and ignore unsystematic differences or noise that may be caused by the stochasticity introduced by the switching probability $\psi$.^[<!--Open footnote-->Note that this is quite a hard assumption that works for this simulation but will be hardly met for empirical data, where heterogeneity among people is common. If heterogeneity is assumed, hierarchical implementation of CPT may be used [cf. @nilssonHierarchicalBayesianParameter2011] <!--Close footnote-->.]
To facilitate comparisons across parameter combinations of the sampling and accumulation models, uninformative prior distributions were used throughout for all four parameters.
Specifically, the prior distributions $\alpha \sim U(0,1)$, $\gamma \sim U(0,2)$, $\delta \sim U(0,10)$, and $\rho \sim U(0,5)$ were used.

```{r convergence-statistics, include=FALSE}
effsize <- min(cpt$n.eff)
rhat <- round(max(cpt$Rhat), 4)
``` 

To estimate the posterior distributions of the free parameters, Markov Chain Monte Carlo sampling as implemented in `JAGS` was used, where 20 chains of 40,000 samples each were run after a warm-up period of 1000 samples.
To reduce potential autocorrelation during the sampling process, only every 20th sample was kept (thinning), leaving a total of 40,000 samples across chains.
The minimum effective sample size was `r format(effsize, big.mark=",", trim=TRUE)`.
The potential scale reduction factor $\hat{R}$ [@gelmanInferenceIterativeSimulation1992] was $\leq$ `r rhat` for all models and parameters, indicating good convergence.

## Model Predictions

Below, the round-wise and the summary integration model are discussed separately.
However, except for the choice rates, displayed in Figures\ \@ref(fig:choice-rates-roundwise) and \@ref(fig:choice-rates-summary), the results of both models are reported in the same figures using a green and blue color-coding for the round-wise and the summary integration model, respectively.

### Round-Wise Integration Model

Overall, the results of the simulations (model predictions) match the expectations formulated in Table\  \@ref(tab:expectations-roundwise), however, with some exceptions concerning the estimates for the parameter $\delta$ of the weighting function.
First, it is inspected how the lengths of the sampling and accumulation processes---measured in the number of sampled outcomes---change with varying combinations of the switching probability $\psi$ and threshold $\theta$.

#### Number of Sampled Outcomes

Figure\ \@ref(fig:sample-sizes) displays the number of outcomes sampled over the course of a sampling and accumulation process for each combination of switching probabilities and thresholds.
The model predicts a decrease in the overall number of sampled outcomes with increases in the switching probability, whereas the overall number of sampled outcomes is predicted to increase with thresholds at a relatively constant rate.
These differences in the number of sampled outcomes are subtle indicators for how sampling strategies and the mechanisms of the round-wise integration model act together to imply different final choices.
Essentially, they foreshadow how the round-wise integration model accumulates evidence for differences in the latent EV for low switching probabilities, and for differences in the latent probability to produce a higher outcome most of the time for high switching probabilities.

Consider also the dashed horizontal lines, which display the median number of 14 outcomes that @wulffMetaanalyticReviewTwo2018 found to be sampled in 10,712 trials involving a choice between a safe and a two-outcome prospect in the sampling paradigm:
The parameter combinations that closely resemble the links between the sampling and decision strategies originally proposed by Hills and Hertwig [-@hillsInformationSearchDecisions2010]---i.e, high switching probabilities and thresholds for piecewise sampling and round-wise decisions vs. low switching probabilities and a single mean comparison ($\theta = 1$) for comprehensive sampling and summary decisions---lead to overall numbers of sampled outcomes that come close to the meta-analytic median.

```{r chain-length, include=FALSE, cache=TRUE}

# labeller functions
label_theta <- function(string) {
  TeX(paste("$\\theta=$", string, sep = "")) #threshold parameter theta
}

chain_lengths <- choices_absolute %>%
  ggplot(aes(x = s, y = n_sample, color = model)) +
  facet_wrap(~a, nrow = 2, scales = "free", labeller = labeller(a = as_labeller(label_theta, default = label_parsed))) + 
  labs(x = expression(paste("Switching Probability ", psi)),
       y = "Number of Sampled Outcomes",
       color = "Model") + 
  scale_x_continuous(limits = c(0,1), breaks = seq(0,1,.5)) +
  geom_jitter(alpha = .05) + 
  geom_smooth(color = "gray", size = 1) + 
  geom_hline(yintercept = 14, linetype = "dashed", color = "gray", size = 1) +
  scale_color_manual(values = c("#35b779" ,"#3e4989")) + 
  guides(color = guide_legend(override.aes = list(alpha = 1))) +
  theme_minimal()

chain_lengths
```

\begin{figure}[t!]
\caption{Lengths of the Sampling and Accumulation Processes}
\includegraphics[width=1\linewidth]{manuscript_files/sample-sizes} \label{fig:sample-sizes}
\raggedright \textit{Note.} Each point represents a single sampling and accumulation process (choice trial) for the respective combination of thresholds and switching probabilities, and is the overall number of outcomes sampled over the course of this process. The gray lines are estimates of \textit{ggplot2}'s \texttt{stat\_smooth()} function. All gray-dashed horizontal lines represent the meta-analytic median for choices between a safe and a risky prospect, found by \protect\hyperlink{ref-wulffMetaanalyticReviewTwo2018}{Wulff et al., 2018}. Note that for better resolution the scales on the y-axis differ for the levels of \(\theta\).
\end{figure}

#### Final Choice

For each combination of switching probabilities and thresholds, Figure\ \@ref(fig:choice-rates-roundwise) displays the rates of choices that did not maximize the sampled mean (i.e., the mean across all outcomes sampled over the course of a sampling and accumulation process, hereafter: false response rates).
Rates are separated for presence and rank of small-probability outcomes.
Consider first the top panel showing the false response rates across all problems where the low-rank outcome of the risky prospect possesses a small probability:
For high switching probabilities, the low-rank outcome was expected to be sampled less often than would be objectively warranted *within each* comparison round, leading to an inflation of the respective round means of the risky prospect.
Accordingly, the top panels show that for each threshold the rates of false choices of the risky prospect increase with the switching probability, causing deviations from sampled mean maximization that take the form of an as-if underweighting of rare outcomes.
In turn, rates of false safe choices remain low.
To demonstrate how the false response rates would have turned out given the normative solutions of EV maximization (i.e., when sampling error is not controlled for), the rates of choices that did not maximize the latent EV are displayed in gray.
Here, a similar but more severe pattern can be found, showing that sampling error exercises an influence independent of the effects implied by the interplay of the sampling strategies and the round-wise integration/decision strategy.
Note from the middle panel that the pattern of false response rates reverses for problems where the high-rank outcome of the risky prospect possesses a small probability.
In this case, then, the means of the risky prospect within each comparison round tend to be more deflated the higher the switching probability, which increases the risk of falsely choosing the safe prospect.
Again, the resulting choice patterns resemble an as-if underweighting of rare outcomes pattern.
Importantly, note from the reduced false response rates in the bottom panel, that the inflation and deflation of the means for high switching probabilities must be significantly attenuated when the prospects possess no small-probability outcome.

In sum, then, the simulated choices show that the potential interplay between sampling strategies and a round-wise integration/decision strategy can lead to distinct choice patterns and as-if weighting patterns in DFE, which, however, strongly depend on the structure of the choice problems.
For small switching probabilities, the round-wise integration model accumulates evidence for differences in the latent EVs, which is reflected in low false response rates.
For high switching probabilities, the round-wise integration model accumulates evidence for differences in the latent probability to produce a higher outcome most of the time.
This is reflected in low false response rates, if the respective prospect also possesses the higher latent EV, otherwise in high false response rates. 

```{r choice-rates-roundwise, include=FALSE, cache=TRUE}
#prepare data

## determine normative choice according to latent EV and sampled mean

### latent EV

fr_rates_EV <- choices_absolute %>%
  filter(model == "roundwise") %>% 
  mutate(norm = case_when(ev_ratio > 1 ~ "A", ev_ratio < 1 ~ "B")) %>% # determine normative choice
  filter(!is.na(norm)) %>% #exclude trials with equal EV
  group_by(s, boundary, a, rare, norm, choice) %>% #separate by model parameter and type of rare event
  summarise(n = n()) %>%
  mutate(rate = round(n/sum(n), 2), #compute response rates
         type = case_when(norm == "A" & choice == "B" ~ "Safe", #determine false response type
                          norm == "B" & choice == "A" ~ "Risky")) %>%
  ungroup() %>%
  filter(!is.na(type)) %>% #remove correct responses
  select(-c(norm, choice, n)) %>% 
  mutate(rare = case_when(rare == "none" ~ "\\in \\[.2,.8\\]", #change facet labels for rare events
                          rare == "attractive" ~ "\\in (0,.2)",
                          rare == "unattractive" ~ "\\in (.8,1)"),
         Norm = "EV")

### sampled mean

fr_rates_mean <- choices_absolute %>% 
  filter(model == "roundwise") %>% 
  mutate(norm = case_when(a_ev_exp/b_ev_exp > 1 ~ "A", a_ev_exp/b_ev_exp < 1 ~ "B")) %>% # determine normative choice
  filter(!is.na(norm)) %>% #exclude trials with equal EV
  group_by(s, boundary, a, rare, norm, choice) %>% #separate by model parameter and type of rare event
  summarise(n = n()) %>%
  mutate(rate = round(n/sum(n), 2), #compute response rates
         type = case_when(norm == "A" & choice == "B" ~ "Safe", #determine false response type
                          norm == "B" & choice == "A" ~ "Risky")) %>%
  ungroup() %>%
  filter(!is.na(type)) %>% #remove correct responses
  select(-c(norm, choice, n)) %>% 
  mutate(rare = case_when(rare == "none" ~ "\\in \\[.2,.8\\]", #change facet labels for rare events
                          rare == "attractive" ~ "\\in (0,.2)",
                          rare == "unattractive" ~ "\\in (.8,1)"),
         Norm = "Mean")

fr_rates <- bind_rows(fr_rates_EV, fr_rates_mean)

# labeller functions
label_theta <- function(string) {
  TeX(paste("$\\theta=$", string, sep = "")) #threshold parameter theta
}

label_rare <- function(string) {
  TeX(paste("$\\p_{High}$", string, sep = "")) #type of rare event
}

#plot

fr_rates_risky <- fr_rates %>% filter(type == "Risky")
fr_rates_safe <- fr_rates %>% filter(type == "Safe")

fr_rates_risky %>%
  ggplot(aes(s, rate, color = Norm)) +
  facet_grid(rare~a, labeller = labeller(rare = as_labeller(label_rare, default = label_parsed), 
                                         a = as_labeller(label_theta, default = label_parsed))) +
  labs(x = expression(paste("Switching Probability ", psi)),
       y = "False Response Rate",
       color = "Norm",
       shape = "False\nResponse") +
  scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, .5)) +
  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, .5)) +
  geom_point(aes(shape = type), size = 2) +
  geom_line() + 
  geom_point(data = fr_rates_safe, aes(shape = type), size = 2) +
  geom_line(data = fr_rates_safe) +
  scale_shape_manual(values = c(8, 16)) +
  scale_color_manual(values = c("#d3d3d3", "#35b779")) + 
  theme_minimal()
```

\begin{figure}[t!]
\caption{Rates of False Risky and False Safe Choices in the Round-Wise Integration Model}
\includegraphics{manuscript_files/figure-latex/choice-rates-roundwise-1} \label{fig:choice-rates-roundwise}
\raggedright \textit{Note.} For each combination of the switching probability \(\psi\) and the threshold \(\theta\), stars and points represent the rate of choices that did not maximize the latent EV (gray) or the mean across all outcomes sampled over the course of a sampling and accumulation process (green, false response rates). Stars: Rates of choice trials, where the risky prospect was chosen, although the safe prospect produced the greater mean (false risky response). Points: Rates of trials, where the safe prospect was chosen, although the risky prospect produced the greater mean (false safe response). \(p_{high} \in (.8, 1)\): Rates for all choice problems that include a small-probability outcome of low rank. \(p_{high} \in (0, 2)\): Rates for problems that include a small-probability outcome of high rank. \(p_{high} \in [.2, .8]\): Rates for problems that do not include an outcome with a probability < .2.
\end{figure}

#### CPT Parameters

Figure\ \@ref(fig:weighting-parameters) displays the estimated means and the 95%-intervals of the posterior distributions of the curvature parameter $\gamma$ and the elevation parameter $\delta$.
First, note that the estimates for the parameter combination $\theta = 1$ and $\psi = 1$ have large posterior intervals.
In these cases, no relative frequencies other than 0 and 1 are supplied to the weighting function, which may explain that the values in between cannot be reliably accounted for.
For $\theta = 1$ and $\psi < 1$, the estimates imply a linear weighting pattern, since in this case only a single round of comparison is carried out and therefore the round-wise integration strategy always chooses the prospect that produces the larger mean across all outcomes sampled over the course of a sampling and accumulation process.
This result is well in line with the explanation that if the mind were to infer the latent objective probabilities of outcomes from the sampled relative frequencies and to follow the principle of EV maximization, sampling error can account for any deviations from it.
In this regard, note also Figure\ \@ref(fig:choice-rates-roundwise), where there are no choices for $\theta = 1$ that do not maximize the sampled mean.

For $\theta > 1$, the curvature parameter $\gamma$ takes values $\geq 1$ which increase with switching probabilities, resulting in a increasingly pronounced S-shaped weighting function.
In other words, the higher the switching probability, the more severe is the underweighting (overweighting) of the high-rank outcome of the risky prospect in CPT, if it is of small (large) probability.
That is, the as-if underweighting of rare outcomes pattern indicated by the final choices (i.e., the false response rates) translates rather directly to an underweighting of small-probability outcomes in CPT.
As expected, the elevation parameter $\delta$ takes no values $< 1$, however, the estimates increase slightly with switching probabilities, causing the overweighting of the high-rank outcome of the risky prospect to extend across the mid-point of the probability scale.
It is open for discussion whether this extension of overweighting beyond the mid-point is theoretically implied by the mechanisms of the round-wise integration model:
That is, for high switching probabilities, the model is expected to choose the risky prospect, if the probability of its high-rank outcome is $> .5$.
To account for the implied choice behavior, CPT might have to overweight high-rank outcomes with a probability far larger than .5 less severely than high-rank outcomes with a probability only a little larger than .5. 
Such a pattern is implied for $\delta > 1$.
Leaving this open issue, the estimates for the $\gamma$ and $\delta$ parameter show that the choices implied by the potential interplay of different sampling strategies and the round-wise integration/decision strategy can lead to distinct signatures in CPT's weighting function (see Figure\ \@ref(fig:function-forms), for the resulting graphs of the weighting function).
Once again, these signatures cannot be due to sampling error.

```{r weighting-parameters, include=FALSE, cache=TRUE}

label_theta <- function(string) {
  TeX(paste("$\\theta=$", string, sep = "")) #threshold parameter theta
}

# plot gamma estimates
gamma <- cpt_absolute %>%
  filter(parameter == "gamma") %>%
  ggplot(aes(s, mean, color = model)) +
  facet_wrap(~a, nrow = 2, labeller = labeller(a = as_labeller(label_theta, default = label_parsed)), scales = "free") +
  scale_x_continuous(limits = c(0,1), breaks = seq(0,1,.5)) + 
  labs(x = expression(paste("Switching Probability ", psi)), 
       y = expression(gamma),
       color = "Model") +
  geom_errorbar(aes(ymin=`2.5%`, ymax=`97.5%`)) + 
  geom_point() +
  geom_line() +
  scale_color_manual(values = c("#35b779" ,"#3e4989")) + 
  theme_minimal()

# plot delta estimates
delta <- cpt_absolute %>%
  filter(parameter == "delta") %>%
  ggplot(aes(s, mean, color = model)) +
  facet_wrap(~a, nrow = 2, labeller = labeller(a = as_labeller(label_theta, default = label_parsed)), scales = "free") +
  scale_x_continuous(limits = c(0,1), breaks = seq(0,1,.5)) + 
  labs(x = expression(paste("Switching Probability ", psi)), 
       y = expression(delta),
       color = "Model") +
  geom_errorbar(aes(ymin=`2.5%`, ymax=`97.5%`)) + 
  geom_point() +
  geom_line() +
  scale_color_manual(values = c("#35b779" ,"#3e4989")) + 
  theme_minimal()

# merge plots
ggarrange(gamma, delta, ncol = 1, nrow = 2, common.legend = TRUE, legend = "right")
```

\begin{figure}[t!]
\caption{Parameter Estimates of the Weighting Function}
\includegraphics{manuscript_files/figure-latex/weighting-parameters-1} \label{fig:weighting-parameters}
\raggedright \textit{Note.} For each combination of the switching probability \(\psi\) and the threshold \(\theta\), points represent the means of the posterior distributions. Error bars represent the 95\%-intervals of the posterior distributions. Note that for better resolution the scales on the y-axis differ for different levels of \(\theta\).
\end{figure}

Figure\ \@ref(fig:sensitivity-parameters) displays the estimated means and the 95%-intervals of the posterior distributions of the outcome sensitivity parameter $\alpha$ and the choice sensitivity parameter $\rho$.
As expected, an increase in the switching probability leads to a decrease in $\alpha$, showing that the round-wise integration model largely ignores outcome information if choices are based on ordinal comparisons of single outcomes rather than of means across larger sets of sampled outcomes.
In other words, for high switching probabilities, the round-wise integration model is expected to choose the prospect that produces the higher outcome most of the time.
Once it is established which prospect does so, it is of no more utility to know the exact magnitude of the difference in the outcomes.
This resonates well with the proposition that round-wise and summary decision strategies are differently equipped to meet short-term and long-term aspirations [cf. @hillsInformationSearchDecisions2010; @wulffHowShortLongrun2015].
The corresponding shape of the value function is shown in Figure\ \@ref(fig:function-forms) and is more concave for high switching probabilities. 
Thus, the estimates for the outcome sensitivity parameter $\alpha$ show that the potential interplay between different sampling strategies and the round-wise integration/decision strategy may lead to choice patterns that also translate to distinct signatures in CPT's value function.

Finally, $\rho$ varied systematically such that the choices were more sensitive to the valuations of the core CPT model for low switching probabilities.
However, for high switching probabilities, the choices did not appear to be random whatsoever.

```{r sensitivity-parameters, include=FALSE, cache=TRUE}

# plot alpha estimates
alpha <- cpt_absolute %>%
  filter(parameter == "alpha") %>%
  ggplot(aes(s, mean, color = model)) +
  facet_wrap(~a, nrow = 2, labeller = labeller(a = as_labeller(label_theta, default = label_parsed)), scales = "free") +
  scale_x_continuous(limits = c(0,1), breaks = seq(0,1,.5)) + 
  labs(x = expression(paste("Switching Probability ", psi)), 
       y = expression(alpha),
       color = "Model") +
  geom_errorbar(aes(ymin=`2.5%`, ymax=`97.5%`)) + 
  geom_point() +
  geom_line() +
  scale_color_manual(values = c("#35b779" ,"#3e4989")) + 
  theme_minimal()

# plot rho estimates
rho <- cpt_absolute %>%
  filter(parameter == "rho") %>%
  ggplot(aes(s, mean, color = model)) +
  facet_wrap(~a, nrow = 2, labeller = labeller(a = as_labeller(label_theta, default = label_parsed)), scales = "free") +
  scale_x_continuous(limits = c(0,1), breaks = seq(0,1,.5)) + 
  labs(x = expression(paste("Switching Probability ", psi)), 
       y = expression(rho),
       color = "Model") +
  geom_errorbar(aes(ymin=`2.5%`, ymax=`97.5%`)) + 
  geom_point() +
  geom_line() +
  scale_color_manual(values = c("#35b779" ,"#3e4989")) + 
  theme_minimal()

# merge plots
ggarrange(alpha, rho, ncol = 1, nrow = 2, common.legend = TRUE, legend = "right") 
```

\begin{figure}[t!]
\caption{Parameter Estimates of the Outcome and Choice Sensitivity Parameter}
\includegraphics{manuscript_files/figure-latex/sensitivity-parameters-1} \label{fig:sensitivity-parameters}
\raggedright \textit{Note.} For each combination of the switching probability \(\psi\) and the threshold \(\theta\), points represent the means of the posterior distributions. Error bars represent the 95\%-intervals of the posterior distributions. Note that for better resolution the scales on the y-axis differ for different levels of \(\theta\).
\end{figure}

```{r function-forms, include=FALSE, cache=TRUE}

# plot weighting function

## compute decision weights

weights <- cpt_absolute %>%
  select(model, s, boundary, a, parameter, mean) %>%
  pivot_wider(names_from = parameter, values_from = mean) %>%
  select(-c(alpha, rho)) %>%
  expand_grid(p = seq(0, 1, .05)) %>%
  mutate(w = round(  (delta * p^gamma)/ ((delta * p^gamma)+(1-p)^gamma), 2))

## plot graphs

wf <- weights %>% 
  ggplot(aes(p, w, group = s, color = s)) +
  facet_wrap(~model~a, nrow = 2, labeller = labeller(a = as_labeller(label_theta, default = label_parsed))) + 
  labs(x = "Experienced Probability",
       y = expression(paste("Decision Weight ", pi)),
       color = expression(paste("Switching\nProbability ", psi))) +
  scale_x_continuous(breaks = seq(0, 1, .5)) +
  scale_y_continuous(breaks = seq(0, 1, .5)) +
  geom_line(size = .5) +
  scale_color_viridis(option = "mako") +
  theme_minimal()
  
# value functions

values <- cpt_absolute %>%
  select(model, s, boundary, a, parameter, mean) %>%
  pivot_wider(names_from = parameter, values_from = mean) %>%
  select(-c(gamma, delta, rho)) %>%
  expand_grid(x = seq(0, 20, .5)) %>%  
  mutate(v = round(x^alpha, 2)) 

vf <- values %>% 
  ggplot(aes(x, v, group = s, color = s)) +
  facet_wrap(model~a, nrow = 2, labeller = labeller(a = as_labeller(label_theta, default = label_parsed))) + 
  labs(x = "Objective Outcome",
       y = "Subjective Value",
       color= expression(paste("Switching\nProbability ", psi))) +
  scale_x_continuous(limits = c(0,20), breaks = seq(0, 20, 10)) +
  geom_line(size = .5) +
  scale_color_viridis(option = "mako") +
  theme_minimal()

# merge plots
ggarrange(wf, vf, ncol = 1, nrow = 2, common.legend = TRUE, legend = "right")
```

\begin{figure}[t!]
\caption{Estimated Graphical Shape of CPT's Weighting and Value Function}
\includegraphics{manuscript_files/figure-latex/function-forms-1} \label{fig:function-forms}
\raggedright \textit{Note.} All displayed graphs are computed on the basis of the parameter values that were estimated for the respective model and combination of the switching probability \(\psi\) and the threshold \(\theta\).
\end{figure}

### Summary Integration Model

As expected, the choice behavior exercised by the summary integration model is less systematic than that of the round-wise integration model, especially for low switching probabilities.
The random choice behavior is indicated by false response rates around the value of .5 (see Fig.\ \@ref(fig:choice-rates-summary)) and low estimates for the choice sensitivity parameter $\rho$ (see Fig.\ \@ref(fig:sensitivity-parameters)).
Because choices become more systematic with increasing switching probabilities, randomness is likely to be caused by the temporal advantage that one of the prospects gains by chance.
For high switching probabilities, choice rates and parameter estimates are roughly in line with the expectations formulated in Table\  \@ref(tab:expectations-summary).

#### Number of Sampled Outcomes

The model predicts the number of outcomes sampled over the course of a sampling and accumulation process to increase with thresholds (see Fig.\ \@ref(fig:sample-sizes)).
As indicated by the gray smoothed functions and the dashed horizontal line, the number of sampled outcomes tends to be generally small and reaches the meta-analytic median found by @wulffMetaanalyticReviewTwo2018 only for higher thresholds.^[<!--Open footnote-->
This may indicate that the thresholds used to generate the choice data were set too low.
However, note that, in contrast to the round-wise integration model, thresholds in the summary integration model are in the same unit as the outcomes.
Given a particular threshold, the number of sampled outcomes required to reach the threshold can vary substantially between choice problems.
<!--Close footnote-->]
Switching probabilities are not predicted to have a meaningful impact on the number of sampled outcomes.
Since the summary integration model assumes that all outcomes sampled from a prospects are integrated into the same cumulative sum, this is already a strong indicator that changes in the sampling strategy should not cause the model to make systematically different choices.

#### Final Choice

For each combination of switching probabilities and thresholds, Figure\ \@ref(fig:choice-rates-summary) displays the rates of choices that did not maximize the sampled mean.
As for the round-wise integration model, rates are separated for presence and rank of small-probability outcomes.
Consider first the bottom panel, which displays the false response rates for all choice problems in which the risky prospect does not possess an outcome with a probability $< .2$:
False response rates decrease with increasing switching probabilities, transitioning from random choice behavior at rates around .5 for low switching probabilities to a systematic maximization of the sampled mean for high switching probabilities.
This actually demonstrates that changes in the sampling strategies do not cause the summary integration model to make systematically different choices.
Specifically: The mechanisms of the summary integration model are such that evidence is accumulated for difference in the latent EVs, given that approximately the same number of outcomes is sampled from *both* prospects.
The more outcomes are sampled from both prospects, i.e., the higher the thresholds, the more accurately these differences should be assessed.
Changes in the sampling strategy do not change the latent property for which evidence is accumulated in the summary integration model.
Rather, they affect whether approximately the same number of outcomes is sampled from both prospects or whether one of the prospects obtains, by chance, a temporal advantage, rendering the decision either systematic or unsystematic, respectively.

In sum, then, the differences compared to the round-wise integration model are striking: 
For the round-wise integration model, changes in the sampling strategy alter the degree to which evidence is sampled for one or the other latent property, which can translate to systematically different choices.
That is, for low switching probabilities, the round-wise integration model accumulates evidence for differences in the latent EV's, resulting in similar choice patterns (false response rates) as produced by the summary integration model.
For high switching probabilities, however, the round-wise integration model accumulates evidence for differences in the latent property to produce a higher outcome most of the time. 
Depending on the structure of the choice problem, this implies an as-if underweighting of rare outcomes pattern, even if sampling error is controlled for.
In contrast, neither do the mechanisms of the summary integration model imply that evidence is systematically sampled for differences in the latent probability to produce a higher outcome most of a time, nor does it predict an as-if underweighting of rare outcomes pattern ones sampling error is controlled for. 
The false response rates displayed in the top and middle panel of Figure\ \@ref(fig:choice-rates-summary), where choice problems include prospects possessing a small-probability outcome, provide support for this notion.

```{r choice-rates-summary, include=FALSE, cache=TRUE}
#prepare data

## determine normative choice according to latent EV and sampled mean

### latent EV

fr_rates_EV <- choices_absolute %>%
  filter(model == "summary") %>% 
  mutate(norm = case_when(ev_ratio > 1 ~ "A", ev_ratio < 1 ~ "B")) %>% # determine normative choice
  filter(!is.na(norm)) %>% #exclude trials with equal EV
  group_by(s, boundary, a, rare, norm, choice) %>% #separate by model parameter and type of rare event
  summarise(n = n()) %>%
  mutate(rate = round(n/sum(n), 2), #compute response rates
         type = case_when(norm == "A" & choice == "B" ~ "Safe", #determine false response type
                          norm == "B" & choice == "A" ~ "Risky")) %>%
  ungroup() %>%
  filter(!is.na(type)) %>% #remove correct responses
  select(-c(norm, choice, n)) %>% 
  mutate(rare = case_when(rare == "none" ~ "\\in \\[.2,.8\\]", #change facet labels for rare events
                          rare == "attractive" ~ "\\in (0,.2)",
                          rare == "unattractive" ~ "\\in (.8,1)"),
         Norm = "EV")

### sampled mean

fr_rates_mean <- choices_absolute %>% 
  filter(model == "summary") %>% 
  mutate(norm = case_when(a_ev_exp/b_ev_exp > 1 ~ "A", a_ev_exp/b_ev_exp < 1 ~ "B")) %>% # determine normative choice
  filter(!is.na(norm)) %>% #exclude trials with equal EV
  group_by(s, boundary, a, rare, norm, choice) %>% #separate by model parameter and type of rare event
  summarise(n = n()) %>%
  mutate(rate = round(n/sum(n), 2), #compute response rates
         type = case_when(norm == "A" & choice == "B" ~ "Safe", #determine false response type
                          norm == "B" & choice == "A" ~ "Risky")) %>%
  ungroup() %>%
  filter(!is.na(type)) %>% #remove correct responses
  select(-c(norm, choice, n)) %>% 
  mutate(rare = case_when(rare == "none" ~ "\\in \\[.2,.8\\]", #change facet labels for rare events
                          rare == "attractive" ~ "\\in (0,.2)",
                          rare == "unattractive" ~ "\\in (.8,1)"),
         Norm = "Mean")

fr_rates <- bind_rows(fr_rates_EV, fr_rates_mean)

# labeller functions
label_theta <- function(string) {
  TeX(paste("$\\theta=$", string, sep = "")) #threshold parameter theta
}

label_rare <- function(string) {
  TeX(paste("$\\p_{High}$", string, sep = "")) #type of rare event
}

#plot

fr_rates_risky <- fr_rates %>% filter(type == "Risky")
fr_rates_safe <- fr_rates %>% filter(type == "Safe")

fr_rates_risky %>%
  ggplot(aes(s, rate, color = Norm)) +
  facet_grid(rare~a, labeller = labeller(rare = as_labeller(label_rare, default = label_parsed), 
                                         a = as_labeller(label_theta, default = label_parsed))) +
  labs(x = expression(paste("Switching Probability ", psi)),
       y = "False Response Rate",
       color = "Norm",
       shape = "False\nResponse") +
  scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, .5)) +
  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, .5)) +
  geom_point(aes(shape = type), size = 2) +
  geom_line() + 
  geom_point(data = fr_rates_safe, aes(shape = type), size = 2) +
  geom_line(data = fr_rates_safe) +
  scale_shape_manual(values = c(8, 16)) +
  scale_color_manual(values = c("#d3d3d3", "#3e4989")) + 
  theme_minimal()
```

\begin{figure}[t!]
\caption{Rates of False Risky and False Safe Choices in the Summary Integration Model}
\includegraphics{manuscript_files/figure-latex/choice-rates-summary-1} \label{fig:choice-rates-summary}
\raggedright \textit{Note.} For each combination of the switching probability \(\psi\) and the threshold \(\theta\), stars and points represent the rate of choices that did not maximize the latent EV (gray) or the mean across all outcomes sampled over the course of a sampling and accumulation process (blue, false response rates). Stars: Rates of choice trials, where the risky prospect was chosen, although the safe prospect produced the greater mean (false risky response). Points: Rates of trials, where the safe prospect was chosen, although the risky prospect produced the greater mean (false safe response). \(p_{high} \in (.8, 1)\): Rates for all choice problems that include a small-probability outcome of low rank. \(p_{high} \in (0, 2)\): Rates for problems that include a small-probability outcome of high rank. \(p_{high} \in [.2, .8]\): Rates for problems that do not include an outcome with a probability < .2.
\end{figure}

#### CPT Parameters

Note that the estimates for the choice sensitivity parameter $rho$ tend to be low for small switching probabilities (see Fig.\ \@ref(fig:sensitivity-parameters)), implying that in these cases the highest model fit is achieved, if a random choice is assumed.
Thus, for small switching probabilities, interpretations of the parameter estimates for the core CPT model should be made with great caution (if at all).
For high switching probabilities, the estimates for the weighting function's $\gamma$ and $\delta$ parameter and the value function's $\alpha$ parameter indicate a linear weighting of sampled relative frequencies and outcomes, i.e., $\gamma \approx 1, \delta \approx 1, \alpha \approx 1$.

# Discussion and Conclusion

The aim of this paper was to sketch how the mind might exercise the capacity of making decisions from experience (DFE).
In DFE, people cannot rely on symbolic descriptions of the choice alternatives, but only on samples of past experiences.
One paradigm used to study DFE experimentally is the sampling paradigm, where people can---as much as they want, in the way they want, and without costs---sample the possible outcomes of prospects before making a final choice.
To approach an explanation for how people proceed and choose in such a paradigm, this paper presented two models that integrate the potential interplay between sampling and integration/decision strategies into the sequential sampling framework.

## Summary

Hills and Hertwig [-@hillsInformationSearchDecisions2010] proposed that the way people sample the outcomes of prospects (sampling strategy) may be linked to the way they process the outcomes in order to evaluate the prospects and make a corresponding choice (integration/decision strategy).
Specifically, the authors assumed two potential links between what they considered paradigmatic instances of both types of strategies:
People either switch prospects after each sampled outcome (piecewise sampling) to compare single outcomes over repeated rounds (round-wise integration/decision), or they switch only once between prospects (comprehensive sampling) and make one comparison between the means across all sampled outcomes (summary decision).
The authors provided tentative empirical support for their claim by showing that a larger proportion of the choices of people who, on average, switched infrequently between prospects were better predicted by a summary strategy (rather than a round-wise strategy), and vice versa.
Moreover, the authors discussed and demonstrated in a simulation based on empirical sampling data that round-wise decisions may cause an as-if underweighting of rare outcomes pattern in DFE and thus, contribute to the decision-experience gap.

The current paper extended the original discussion and analyses of Hills and Hertwig [-@hillsInformationSearchDecisions2010] in several ways, notably:

1. No fixed links between particular sampling and decision strategies were assumed, but all possible combinations were considered.

2. The sequential sampling framework was used as a modeling outlet to incorporate the potential interplay between sampling and decision strategies into formal models that offer a complete account of the decision-making process and make theoretical commitments explicit.

3. Cumulative prospect theory was used to model simulated choice data, allowing to inquire whether the choices implied by the potential interplay between both types of strategies may translate to characteristic signatures in CPTs psychoeconomic value and weighting function.

4. The structure of choice problems---i.e., the presence and desirability of rare outcomes---was systematically varied.

This paper started from the computational problem the mind is trying to solve in the sampling paradigm, and the principle logic that governs its solution:
In order to make systematic choices between prospects, the mind must assess true differences in their latent properties, and it can only do so by searching for evidence in information samples.
Relying on the sequential sampling framework, the current paper assumed that this search process takes the form of an evidence accumulation over time, where outcomes are sampled until the accumulated evidence reaches a threshold.
Two different models were presented, each of which assumes an accumulation process that resembles a distinct integration/decision strategy.
The round-wise integration model assumes that the means across sets of sampled outcomes are repeatedly compared and a choice is made once the number of won comparisons reaches a threshold.
The summary integration model assumes that all outcomes sampled from a prospect are integrated into the same cumulative sum and that a choice is made once the sum reaches a threshold.

The current paper discussed and demonstrated in a computational analysis how sampling strategies may or may not alter the latent property for which each of the models accumulates evidence, and thus may or may not cause each model to produce systematically different choice patterns:
In the round-wise integration model, changes in the sampling strategy alter the degree to which evidence is accumulated for differences in either the expected values or in the probability to produce a higher outcome most of the time.
Accordingly, the simulations showed that low switching probabilities lead the round-wise integration model to make choices in line with EV maximization, whereas high switching probabilities lead the model to produce systematic deviations from EV maximization taking the form of an as-if underweighting of rare outcomes, even if sampling error is controlled for. 
In contrast, in the summary integration model, evidence is, in principal, accumulated for differences in the latent EVs.
Accordingly, the simulations showed that high switching probabilities lead the model to make choices in line with EV maximization. 
However, low switching probabilities have been shown to introduce random temporal imbalances between the prospects regarding the amount of evidence that can be sampled, resulting in choices that are less sensitive to differences in the EVs but rather unsystematic.

Finally, the current paper demonstrated how the effects of the potential interplay between sampling and integration/decision strategies on the final choice can translate to characteristic signatures in cumulative prospect theory's value and weighting function.
Having controlled for sampling error, the estimated CPT parameters and the resulting function shapes primarily reflected how sensitive the different  combinations of sampling and integration/decision strategies are to particular changes in the outcomes and their probabilities.

## Why Sampling and Decision Strategies and Why Particular Links?

This concluding section intends to briefly draw attention to one particular limitation of the current paper and to what may be gained from overcoming it.
Of course, this paper is purely theoretical, and the validity of its claims and simulations eventually depends on whether they stand the test of empirical data.
Here, however, the concern is less about the current lack of an empirical test, but that more could have been done and should be done in future work to endow the idea of an interplay between sampling and integration/strategies with theoretical plausibility.

In explaining cognitive capacities, such as decision making from experience, models thereof must be constrained to the extent that neither the computational resources of the human mind nor other relevant resources---e.g., time---are limitless [see, e.g., @jareckiFrameworkBuildingCognitive2020; @liederResourcerationalAnalysisUnderstanding2020; @vanrooijTheoryTestHow2021].
Acknowledging these limitations, different theoretical frameworks can be used to narrow down the still abundant number of possible mechanisms the mind might employ in the decision-making process.
Such frameworks build on different, sometimes related or complementary assumptions, e.g.:
*ecological rationality* holds that the mind uses simple (decision) heuristics that exploit the information structures of the environment in which it operates [@payneAdaptiveStrategySelection1988; see also @simonRationalChoiceStructure1956];
several sequential sampling models have been shown to implement optimal speed-accuracy trade-offs in that they make the most accurate choices for a given speed or the fastest for a given accuracy [@bogaczPhysicsOptimalDecision2006];
and *resource rationality* assumes that the mind employs mechanisms that make optimal use of its actual resources in obtaining a specific goal [@liederResourcerationalAnalysisUnderstanding2020].

The current paper dealt with these frameworks and their assumptions rather loosely and implicitly.
A thorough and explicit treatment will help to move the idea of an interplay between sampling and integration/decision strategies beyond the "mere" consideration of its effects and endow it with greater theoretical plausibility, even before contact with data. 
That is, the question of why particular sampling and decision strategies might be employed and linked is not at all answered by the choices and weighting patterns they imply.
Rather an answer is approached by showing how the idea of an interplay of both types of strategies can be integrated into the wider study of the computationally limited but adaptive mind.

\newpage

# Acknowledgements

\noindent
I thank Thorsten Pachur and Veronika Zilker for the opportunity of an internship at the Center for Adaptive Rationality at the Max Planck Institute for Human Development in Berlin and for supervising this thesis.

\newpage

# References

<!-- # Appendix --> 

```{r subset-relative, include=FALSE}
choices_relative <- choices %>% filter(boundary == "relative")
cpt_relative <- cpt %>% filter(boundary == "relative")
```

<!-- ## False Response Rates -->

```{r choice-rates-roundwise-relative, include=FALSE, cache=TRUE}
#prepare data

## determine normative choice according to latent EV and sampled mean

### latent EV

fr_rates_EV <- choices_relative %>%
  filter(model == "roundwise") %>% 
  mutate(norm = case_when(ev_ratio > 1 ~ "A", ev_ratio < 1 ~ "B")) %>% # determine normative choice
  filter(!is.na(norm)) %>% #exclude trials with equal EV
  group_by(s, boundary, a, rare, norm, choice) %>% #separate by model parameter and type of rare event
  summarise(n = n()) %>%
  mutate(rate = round(n/sum(n), 2), #compute response rates
         type = case_when(norm == "A" & choice == "B" ~ "Safe", #determine false response type
                          norm == "B" & choice == "A" ~ "Risky")) %>%
  ungroup() %>%
  filter(!is.na(type)) %>% #remove correct responses
  select(-c(norm, choice, n)) %>% 
  mutate(rare = case_when(rare == "none" ~ "\\in \\[.2,.8\\]", #change facet labels for rare events
                          rare == "attractive" ~ "\\in (0,.2)",
                          rare == "unattractive" ~ "\\in (.8,1)"),
         Norm = "EV")

### sampled mean

fr_rates_mean <- choices_relative %>% 
  filter(model == "roundwise") %>% 
  mutate(norm = case_when(a_ev_exp/b_ev_exp > 1 ~ "A", a_ev_exp/b_ev_exp < 1 ~ "B")) %>% # determine normative choice
  filter(!is.na(norm)) %>% #exclude trials with equal EV
  group_by(s, boundary, a, rare, norm, choice) %>% #separate by model parameter and type of rare event
  summarise(n = n()) %>%
  mutate(rate = round(n/sum(n), 2), #compute response rates
         type = case_when(norm == "A" & choice == "B" ~ "Safe", #determine false response type
                          norm == "B" & choice == "A" ~ "Risky")) %>%
  ungroup() %>%
  filter(!is.na(type)) %>% #remove correct responses
  select(-c(norm, choice, n)) %>% 
  mutate(rare = case_when(rare == "none" ~ "\\in \\[.2,.8\\]", #change facet labels for rare events
                          rare == "attractive" ~ "\\in (0,.2)",
                          rare == "unattractive" ~ "\\in (.8,1)"),
         Norm = "Mean")

fr_rates <- bind_rows(fr_rates_EV, fr_rates_mean)

# labeller functions
label_theta <- function(string) {
  TeX(paste("$\\theta=$", string, sep = "")) #threshold parameter theta
}

label_rare <- function(string) {
  TeX(paste("$\\p_{High}$", string, sep = "")) #type of rare event
}

#plot

fr_rates_risky <- fr_rates %>% filter(type == "Risky")
fr_rates_safe <- fr_rates %>% filter(type == "Safe")

fr_rates_risky %>%
  ggplot(aes(s, rate, color = Norm)) +
  facet_grid(rare~a, labeller = labeller(rare = as_labeller(label_rare, default = label_parsed), 
                                         a = as_labeller(label_theta, default = label_parsed))) +
  labs(x = expression(paste("Switching Probability ", psi)),
       y = "False Response Rate",
       color = "Norm",
       shape = "False\nResponse") +
  scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, .5)) +
  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, .5)) +
  geom_point(aes(shape = type), size = 2) +
  geom_line() + 
  geom_point(data = fr_rates_safe, aes(shape = type), size = 2) +
  geom_line(data = fr_rates_safe) +
  scale_shape_manual(values = c(8, 16)) +
  scale_color_manual(values = c("#d3d3d3", "#35b779")) + 
  theme_minimal()
```

```{r choice-rates-summary-relative, include=FALSE, cache=TRUE}
#prepare data

## determine normative choice according to latent EV and sampled mean

### latent EV

fr_rates_EV <- choices_relative %>%
  filter(model == "summary") %>% 
  mutate(norm = case_when(ev_ratio > 1 ~ "A", ev_ratio < 1 ~ "B")) %>% # determine normative choice
  filter(!is.na(norm)) %>% #exclude trials with equal EV
  group_by(s, boundary, a, rare, norm, choice) %>% #separate by model parameter and type of rare event
  summarise(n = n()) %>%
  mutate(rate = round(n/sum(n), 2), #compute response rates
         type = case_when(norm == "A" & choice == "B" ~ "Safe", #determine false response type
                          norm == "B" & choice == "A" ~ "Risky")) %>%
  ungroup() %>%
  filter(!is.na(type)) %>% #remove correct responses
  select(-c(norm, choice, n)) %>% 
  mutate(rare = case_when(rare == "none" ~ "\\in \\[.2,.8\\]", #change facet labels for rare events
                          rare == "attractive" ~ "\\in (0,.2)",
                          rare == "unattractive" ~ "\\in (.8,1)"),
         Norm = "EV")

### sampled mean

fr_rates_mean <- choices_relative %>% 
  filter(model == "summary") %>% 
  mutate(norm = case_when(a_ev_exp/b_ev_exp > 1 ~ "A", a_ev_exp/b_ev_exp < 1 ~ "B")) %>% # determine normative choice
  filter(!is.na(norm)) %>% #exclude trials with equal EV
  group_by(s, boundary, a, rare, norm, choice) %>% #separate by model parameter and type of rare event
  summarise(n = n()) %>%
  mutate(rate = round(n/sum(n), 2), #compute response rates
         type = case_when(norm == "A" & choice == "B" ~ "Safe", #determine false response type
                          norm == "B" & choice == "A" ~ "Risky")) %>%
  ungroup() %>%
  filter(!is.na(type)) %>% #remove correct responses
  select(-c(norm, choice, n)) %>% 
  mutate(rare = case_when(rare == "none" ~ "\\in \\[.2,.8\\]", #change facet labels for rare events
                          rare == "attractive" ~ "\\in (0,.2)",
                          rare == "unattractive" ~ "\\in (.8,1)"),
         Norm = "Mean")

fr_rates <- bind_rows(fr_rates_EV, fr_rates_mean)

# labeller functions
label_theta <- function(string) {
  TeX(paste("$\\theta=$", string, sep = "")) #threshold parameter theta
}

label_rare <- function(string) {
  TeX(paste("$\\p_{High}$", string, sep = "")) #type of rare event
}

#plot

fr_rates_risky <- fr_rates %>% filter(type == "Risky")
fr_rates_safe <- fr_rates %>% filter(type == "Safe")

fr_rates_risky %>%
  ggplot(aes(s, rate, color = Norm)) +
  facet_grid(rare~a, labeller = labeller(rare = as_labeller(label_rare, default = label_parsed), 
                                         a = as_labeller(label_theta, default = label_parsed))) +
  labs(x = expression(paste("Switching Probability ", psi)),
       y = "False Response Rate",
       color = "Norm",
       shape = "False\nResponse") +
  scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, .5)) +
  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, .5)) +
  geom_point(aes(shape = type), size = 2) +
  geom_line() + 
  geom_point(data = fr_rates_safe, aes(shape = type), size = 2) +
  geom_line(data = fr_rates_safe) +
  scale_shape_manual(values = c(8, 16)) +
  scale_color_manual(values = c("#d3d3d3", "#3e4989")) + 
  theme_minimal()
```

<!-- ## Parameter Estimates and CPT Graphs -->

```{r weighting-parameters-relative, include=FALSE, cache=TRUE}

label_theta <- function(string) {
  TeX(paste("$\\theta=$", string, sep = "")) #threshold parameter theta
}

# plot gamma estimates
gamma <- cpt_relative %>%
  filter(parameter == "gamma") %>%
  ggplot(aes(s, mean, color = model)) +
  facet_wrap(~a, nrow = 2, labeller = labeller(a = as_labeller(label_theta, default = label_parsed)), scales = "free") +
  scale_x_continuous(limits = c(0,1), breaks = seq(0,1,.5)) + 
  labs(x = expression(paste("Switching Probability ", psi)), 
       y = expression(gamma),
       color = "Model") +
  geom_errorbar(aes(ymin=`2.5%`, ymax=`97.5%`)) + 
  geom_point() +
  geom_line() +
  scale_color_manual(values = c("#35b779" ,"#3e4989")) + 
  theme_minimal()

# plot delta estimates
delta <- cpt_relative %>%
  filter(parameter == "delta") %>%
  ggplot(aes(s, mean, color = model)) +
  facet_wrap(~a, nrow = 2, labeller = labeller(a = as_labeller(label_theta, default = label_parsed)), scales = "free") +
  scale_x_continuous(limits = c(0,1), breaks = seq(0,1,.5)) + 
  labs(x = expression(paste("Switching Probability ", psi)), 
       y = expression(delta),
       color = "Model") +
  geom_errorbar(aes(ymin=`2.5%`, ymax=`97.5%`)) + 
  geom_point() +
  geom_line() +
  scale_color_manual(values = c("#35b779" ,"#3e4989")) + 
  theme_minimal()

# merge plots
ggarrange(gamma, delta, ncol = 1, nrow = 2, common.legend = TRUE, legend = "right")
```

```{r sensitivity-parameters-relative, include=FALSE, cache=TRUE}

# plot alpha estimates
alpha <- cpt_relative %>%
  filter(parameter == "alpha") %>%
  ggplot(aes(s, mean, color = model)) +
  facet_wrap(~a, nrow = 2, labeller = labeller(a = as_labeller(label_theta, default = label_parsed)), scales = "free") +
  scale_x_continuous(limits = c(0,1), breaks = seq(0,1,.5)) + 
  labs(x = expression(paste("Switching Probability ", psi)), 
       y = expression(alpha),
       color = "Model") +
  geom_errorbar(aes(ymin=`2.5%`, ymax=`97.5%`)) + 
  geom_point() +
  geom_line() +
  scale_color_manual(values = c("#35b779" ,"#3e4989")) + 
  theme_minimal()

# plot rho estimates
rho <- cpt_relative %>%
  filter(parameter == "rho") %>%
  ggplot(aes(s, mean, color = model)) +
  facet_wrap(~a, nrow = 2, labeller = labeller(a = as_labeller(label_theta, default = label_parsed)), scales = "free") +
  scale_x_continuous(limits = c(0,1), breaks = seq(0,1,.5)) + 
  labs(x = expression(paste("Switching Probability ", psi)), 
       y = expression(rho),
       color = "Model") +
  geom_errorbar(aes(ymin=`2.5%`, ymax=`97.5%`)) + 
  geom_point() +
  geom_line() +
  scale_color_manual(values = c("#35b779" ,"#3e4989")) + 
  theme_minimal()

# merge plots
ggarrange(alpha, rho, ncol = 1, nrow = 2, common.legend = TRUE, legend = "right") 
```

```{r function-forms-relative, include=FALSE, cache=TRUE}

# plot weighting function

## compute decision weights

weights <- cpt_relative %>%
  select(model, s, boundary, a, parameter, mean) %>%
  pivot_wider(names_from = parameter, values_from = mean) %>%
  select(-c(alpha, rho)) %>%
  expand_grid(p = seq(0, 1, .05)) %>%
  mutate(w = round(  (delta * p^gamma)/ ((delta * p^gamma)+(1-p)^gamma), 2))

## plot graphs

wf <- weights %>% 
  ggplot(aes(p, w, group = s, color = s)) +
  facet_wrap(~model~a, nrow = 2, labeller = labeller(a = as_labeller(label_theta, default = label_parsed))) + 
  labs(x = "Experienced Probability",
       y = expression(paste("Decision Weight ", pi)),
       color = expression(paste("Switching\nProbability ", psi))) +
  scale_x_continuous(breaks = seq(0, 1, .5)) +
  scale_y_continuous(breaks = seq(0, 1, .5)) +
  geom_line(size = .5) +
  scale_color_viridis(option = "mako") +
  theme_minimal()
  
# value functions

values <- cpt_relative %>%
  select(model, s, boundary, a, parameter, mean) %>%
  pivot_wider(names_from = parameter, values_from = mean) %>%
  select(-c(gamma, delta, rho)) %>%
  expand_grid(x = seq(0, 20, .5)) %>%  
  mutate(v = round(x^alpha, 2)) 

vf <- values %>% 
  ggplot(aes(x, v, group = s, color = s)) +
  facet_wrap(model~a, nrow = 2, labeller = labeller(a = as_labeller(label_theta, default = label_parsed))) + 
  labs(x = "Objective Outcome",
       y = "Subjective Value",
       color= expression(paste("Switching\nProbability ", psi))) +
  scale_x_continuous(limits = c(0,20), breaks = seq(0, 20, 10)) +
  geom_line(size = .5) +
  scale_color_viridis(option = "mako") +
  theme_minimal()

# merge plots
ggarrange(wf, vf, ncol = 1, nrow = 2, common.legend = TRUE, legend = "right")
```

```{r echo = FALSE, results = 'asis', cache = FALSE}
papaja::render_appendix('manuscript_appendix.Rmd')
```


```{r echo = FALSE, results = 'asis', cache = FALSE}
papaja::render_appendix('manuscript_appendix.Rmd')
```



\newpage

# (APPENDIX) Appendix {-}

```{r child = "manuscript_appendix.Rmd"}
```

